{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c7dd75b",
   "metadata": {},
   "source": [
    "# 트랜스포머로 만드는 대화형 챗봇\n",
    "## 개요\n",
    "트랜스포머 모델의 인코더-디코더 구조를 이해하고, 영어로 된 대화형 챗봇을 만들어봅니다.\n",
    "\n",
    "## 목차\n",
    "1. 챗봇의 개념 및 딥러닝과의 관계\n",
    "2. 트랜스포머와 인코더 디코더\n",
    "3. 트랜스포머의 입력 이해하기\n",
    "4. 어텐션\n",
    "5. 스케일드 닷 프로덕트 어텐션\n",
    "6. 머리가 여러 개인 어텐션\n",
    "7. 마스킹\n",
    "8. 인코더\n",
    "9. 디코더\n",
    "10. 챗봇의 병렬 데이터 받아오기\n",
    "11. 병렬 데이터 전처리하기\n",
    "12. 모델 정의 및 학습하기\n",
    "13. 챗봇 테스트하기\n",
    "\n",
    "## 회고\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cf813d",
   "metadata": {},
   "source": [
    "# 1. 챗봇의 개념 및 딥러닝과의 관계\n",
    "## 대화형 챗봇이란?\n",
    "[챗봇의 5가지 대표 유형](https://tonyaround.com/%ec%b1%97%eb%b4%87-%ea%b8%b0%ed%9a%8d-%eb%8b%a8%ea%b3%84-%ec%b1%97%eb%b4%87%ec%9d%98-5%ea%b0%80%ec%a7%80-%eb%8c%80%ed%91%9c-%ec%9c%a0%ed%98%95-%ec%a2%85%eb%a5%98/)\n",
    "- 대화형 챗봇 : 질문을 분석하여 답변을 주는 프로세스.  인공지능 기반으로 되어 있으며, 머신러닝 및 딥러닝을 기본으로 합니다. 어떤 문장으로 질문을 하면 답변을 전달합니다.\n",
    "- 트리형(버튼) 챗봇 : 정해진 트리구조를 따라 답변을 얻는 형태. 최종 답변을 위한 경우의 수는 정해져 있습니다. 일반적으로 자주하는 질문의 서비스에 사용되는 유형\n",
    "- 추천형 챗봇 : 표면적으로는 대화의 형태를 띄고 있지만, 답변을 제공하는 방식이 대화형 챗봇과 다릅니다. 인공지능 기반일 수도 아닐 수도 있음. 질문을 던지면 대화 형태의 답변을 제공하는 것이 아니라 사전에 정의된 답변의 리스트를 알고리즘 결과의 우선순위별로 보여줍니다. 아니면 단순하게 검색 결과의 리스트 형태로 보여줄 수도 있습니다.\n",
    "- 시나리오형 챗봇 : 원하는 서비스 혹은 아웃풋 제공을 위하여 정해진 시나리오를 수행해주는 챗봇입니다. 최종 결과 전달을 위해서 고객에게 받아야하는 정보를 순서에 따라 받아줍니다. 로그인이라고 하면 아이디를 묻고 데이터를 받고 유효성 체크를 하고 비밀번호를 묻고 데이터를 받고 유효성 체크를 합니다. 단계가 있기 때문에 고객 이탈율 분석을 통해서 고객 경험을 단계별로 향상시킬 수 있습니다.\n",
    "- 결합형 챗봇 : 비즈니스 목적에 따라 위의 챗봇 유형들을 결합해서 설계가 가능.   \n",
    "    \n",
    "|챗봇 유형|비용|전문성|시간|\n",
    "|:-------:|:---:|:----:|:---:|\n",
    "|대화형|매우 높음|매우 높음|매우 높음|\n",
    "|트리형|매우 낮음|낮음|보통|\n",
    "|추천형|보통|보통|많음|\n",
    "|시나리오형|보통|보통|보통|  \n",
    "\n",
    "대화형을 제외하면 사실상 챗봇은 대화형 UX를 가졌지만 본질적으로는 검색엔진이거나, 혹은 음성 ARS를 대화형 UX에 옮겨놓은 것이라 할 수 있습니다.  \n",
    "\n",
    "## 챗봇과 딥러닝\n",
    "- 챗봇에 대한 초창기의 기대, 한계점, 최근 BERT 등의 pretrained model의 발전 이후의 새로운 기대감으로 이어지는 챗봇의 간략한 역사를 확인해보기\n",
    "- 트랜스포머 모델의 활용 : 인간보다 정확하게 퀴즈를 풀어내는 BERT, ALBERT 등은 모두 트랜스포머(Transformer)라는 모델을 활용하여 pretrain을 적용한 것들입니다.\n",
    "- 트랜스포머 이전 : 트랜스포머 이전에도 LSTM 등 RNN 기반의 딥러닝 모델, 그리고 이를 인코더-디코더 구조로 엮은 seq2seq 모델 등을 활용하여 챗봇 제작을 시도해 왔습니다. \n",
    "- 트랜스포머의 장점, 메인 스트림이 된 이유\n",
    "    - 병렬처리에 불리한 LSTM에 비해 훨씬 뛰어난 처리 속도를 보이면서도 \n",
    "    - LSTM 등 RNN 모델이 가지는 장기 의존성에 강건한 특징 때문에 매우 긴 길이의 문장을 처리하는 데 유리하다는 좋은 특징을 보여주었고, \n",
    "    - 이후 자연어처리 분야의 혁신을 가져온 발판이 되어 주었습니다.\n",
    "- 인코더-디코더 구조 모델의 예시 : seq2seq, AutoEncoder, GAN 등\n",
    "- seq2seq 모델을 기반으로 하는 번역기 예시 : 영어를 한국어로 번역하는 모델은 영어 문장을 인코더로 해석하여 나온 벡터를 디코더의 인풋(input)으로 삼아 디코더에서 한국어 문장을 생성하게 합니다. 그런 것처럼 사용자의 입력 문장을 인코더로 해석하고, 적절한 답변 문장을 디코더가 생성하도록 구성할 수 있을 것입니다.\n",
    "- 더욱 좋은 성능을 내기 위해서 필요한 것? : 엄청나게 많은 코퍼스로 학습시킨 pretrained model을 활용하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4005d02e",
   "metadata": {},
   "source": [
    "# 2. 트랜스포머와 인코더 디코더"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45e4151",
   "metadata": {},
   "source": [
    "## 인코더와 디코더 구조 되짚어보기\n",
    "번역기를 만드는 데 사용한 대표적인 모델인 인코더와 디코더 구조를 되짚어 봅시다.    \n",
    "![incoder-decoder](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_UcFQAjh.max-800x600.png)    \n",
    "- 번역기는 인코더와 디코더 두 가지 아키텍처로 구성\n",
    "- 인코더에 입력 문장이 들어가고, \n",
    "- 디코더는 이에 상응하는 출력 문장을 생성합니다. \n",
    "- 이를 훈련한다는 것은 결국 입력 문장과 출력 문장 두 가지 병렬 구조로 구성된 데이터셋을 훈련한다는 의미였습니다.  \n",
    "\n",
    "#### 훈련 데이터셋의 구성(번역)\n",
    "    - 입력 문장 : '저는 학생입니다.'\n",
    "    - 출력 문장 : 'I am a student'    \n",
    "\n",
    "이런 병렬적으로 구성된 데이터셋을 인코더와 디코더로 학습하는 경우는 사실 번역기에만 한정되지는 않습니다.   \n",
    "질문에 대해서 대답을 하도록 구성된 데이터셋을 인코더와 디코더 구조로 학습한다면, 주어진 질문에 답변할 수 있는 챗봇 또한 만들 수 있을 테니까요.  \n",
    "\n",
    "#### 훈련 데이터셋의 구성(질문-답변)\n",
    "    - 입력 문장 : '오늘의 날씨는 어때?'\n",
    "    - 출력 문장 : '오늘은 매우 화창한 날씨야'\n",
    "    \n",
    "## 트랜스포머의 인코더와 디코더\n",
    "트랜스포머 또한 번역기와 마찬가지로 기본적으로 인코더와 디코더 구성을 가지고 있습니다. 입력 문장을 넣으면 출력 문장을 내뱉고 있지요.  \n",
    "![transformer](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_1_kxflIxg.max-800x600.png)  \n",
    "[출처 : http://jalammar.github.io/illustrated-transformer/]  \n",
    "\n",
    "위의 블랙박스로 가려져 있는 트랜스포머의 내부 구조를 열어보면 아래와 같습니다!  \n",
    "![transformer_blackbox](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_2_EnQyi4S.max-800x600.png)  \n",
    "[출처 : http://jalammar.github.io/illustrated-transformer/]  \n",
    "\n",
    "초록색 색깔의 도형을 인코더 층(Encoder layer), 핑크색 색깔의 도형을 디코더(Decoder layer)라고 하였을 때, \n",
    "- 입력 문장은 누적해 쌓아 올린 인코더의 층을 통해서 정보를 뽑아내고, \n",
    "- 디코더는 누적해 쌓아 올린 디코더의 층을 통해서 출력 문장의 단어를 하나씩 만들어가는 구조를 갖고 있어요.  \n",
    "\n",
    "\n",
    "그리고 그 내부를 조금 더 확대해 보면 아래와 같이 톱니바퀴처럼 맞물려 돌아가는 여러 가지 부품들로 구성돼 있습니다.  \n",
    "![incoder-decoder 내부](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_3_ddZedfW.max-800x600.png)  \n",
    "[출처 : http://jalammar.github.io/illustrated-transformer/]  \n",
    "\n",
    "위의 그림에서 적힌 모듈들을 하나씩 정리해 볼까요?  \n",
    "Q. 트랜스포머에서 인코더와 디코더는 어떤 역할을 수행하나요?  \n",
    "A. 인코더는 입력 문장을 임베딩하고 문장의 의미를 파악하여 디코더에 전달합니다. 디코더는 인코더에서 전달 받은 정보를 기반으로 문장을 생성합니다.  \n",
    "\n",
    "**embedding과 incoding**  \n",
    "- Embedding: 토크나이징된 단어 토큰들을 벡터들로 변환하는 과정\n",
    "- Encoding: Embedding된 벡터들을 Sentence Matrix로 변환하는 과정 (주로 Bi-LSTM 이용)\n",
    "- 보통 Encoder에서 Embedding과 Encoding을 모두 수행한다.  \n",
    "[참조 블로그](https://beausty23.tistory.com/223)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4222c55d",
   "metadata": {},
   "source": [
    "# 3. 트랜스포머의 입력 이해하기\n",
    "필요한 패키지를 임포트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3369e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 패키지 임포트\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2e4724",
   "metadata": {},
   "source": [
    "### 모델의 입력 데이터 처리 - 일반 모델과 트랜스퍼 모델의 차이점\n",
    "\n",
    "![인코더디코더](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_4_fuzN6PD.png)  \n",
    "\n",
    "- 많은 자연어 처리 모델들은 텍스트 문장을 입력으로 받기 위해 단어를 임베딩 벡터로 변환하는 벡터화 과정을 거칩니다. \n",
    "- 트랜스포머 또한 벡터화 과정을 거칩니다.\n",
    "- 모델의 입력 데이터 처리에는 트랜스포머 모델이 다른 점 (RNN 계열의 모델들과 다른 점)\n",
    "    - 바로 임베딩 벡터에 어떤 값을 더해준 뒤에 입력으로 사용한다는 점입니다. \n",
    "    - 그 값은 바로 위 그림에서의 포지셔널 인코딩(positional Encoding)에 해당하는 부분입니다.  \n",
    "    \n",
    "\n",
    "위 그림에서 인코더의 입력 부분을 조금 더 확대해 본다면 이런 그림이 나오겠죠?  \n",
    "![인코더 입력 부분](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_5_kH52kQN.png)  \n",
    "\n",
    "### 포지셔널 인코딩을 하는 이유는?\n",
    "- 트랜스포머는 입력을 받을 때, 문장에 있는 단어들을 1개씩 순차적으로 받는 것이 아니라, 문장에 있는 모든 단어를 한꺼번에 입력으로 받기 때문\n",
    "    -> 이 부분이 트랜스포머가 RNN과 결정적으로 다른 점!!!\n",
    "- RNN : RNN에는 어차피 문장을 구성하는 단어들이 어순대로 모델에 입력되므로, 모델에게 따로 어순 정보를 알려줄 필요가 없었습니다.\n",
    "- Transformer \n",
    "    - 단어와 그 단어의 어순 정보(문장의 몇 번째 어순으로 입력되었는지)를 함께 입력으로 삼는다! (같은 단어라고 하더라도)\n",
    "    - 단어의 임베딩 벡터(단어) + 위치 정보를 가진 벡터(Positional Encoding) 값 = 모델의 입력\n",
    "    - 문장에 있는 모든 단어를 한꺼번에 문장 단위로 입력받는 트랜스포머는 자칫 'I ate lunch'와 'lunch ate I'를 구분할 수 없을지도 모르기 때문  \n",
    "\n",
    "![수식](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_6_DyxB6Ax.png)   \n",
    "포지셔널 인코딩의 벡터값은 위의 수식에 의해서 정해집니다.    \n",
    "사인 함수와 코사인 함수의 그래프를 상기해보면 요동치는 값의 형태를 생각해 볼 수 있는데, **트랜스포머는 사인 함수와 코사인 함수의 값을 임베딩 벡터에 더해줌으로써 단어의 순서 정보를 더하여 줍니다.**  \n",
    "\n",
    "위의 두 함수에는 pos,i,d model 등 생소한 변수들이 있습니다.   \n",
    "위의 함수를 이해하기 위해서는 위에서 본 임베딩 벡터와 포지셔널 인코딩의 덧셈은   \n",
    "= 임베딩 벡터가 모여 만들어진 문장 벡터 행렬과 포지셔널 인코딩 행렬의 덧셈 연산을 통해 이루어진다는 점을 이해해야 합니다.\n",
    "\n",
    "![덧셈 연산](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_7_3Rneu0P.png)  \n",
    "- d model 은 임베딩 벡터의 차원을 의미하고 있고, \n",
    "- pos는 입력 문장에서의 임베딩 벡터의 위치를 나타내며, \n",
    "- i는 임베딩 벡터 내의 차원의 인덱스를 의미합니다.   \n",
    "이렇게 임베딩 행렬과 포지셔널 행렬이라는 두 행렬을 더함으로써 각 단어 벡터에 위치 정보를 더해주게 되는 것이죠!  \n",
    "\n",
    "Q. 한 문장에 같은 단어 A가 여러 번 등장하였다고 가정해보겠습니다. 임베딩 문장 행렬에 포지셔널 인코딩을 해주었을 때와 해주지 않았을 때, 트랜스포머가 임베딩 문장 행렬 내의 다수의 A 단어 벡터로부터 얻을 수 있는 정보의 차이는 어떤 것이 있을까요?  \n",
    "A. 같은 단어라고 하더라도 포지셔널 인코딩을 해준 경우에는 임베딩 벡터값이 달라지므로, 같은 단어라고 해도 각각 다른 위치에 등장했다는 사실을 모델에 알려줄 수 있습니다.  \n",
    "\n",
    "## 포지셔널 행렬 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b105df15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    # PositionalEncoding 메서드 : 포지셔널 인코딩을 위한 각도 배열을 생성\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    # positional_encoding 메서드를 호출하여 pos_encoding 변수에 저장\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    # get_anfles 메서드 : 각도 배열을 생성하기 위해 사용. 주어진 위치(position), 인덱스(i), 및 임베딩 차원(d_model)에 대한 각도를 계산.\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "    # positional_encoding : 각도 배열을 생성하고, 짝수 인덱스에는 사인 함수를, 홀수 인덱스에는 코사인 함수를 적용한 후, sin과 cosine이 교차되도록 재배열 \n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    # 입력에 포지셔널 인코딩 값을 더하여 반환. 포지셔널 인코딩의 길이를 입력의 길이에 맞게 자릅니다.\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5470366d",
   "metadata": {},
   "source": [
    "행의 크기가 50, 열의 크기가 512인 행렬을 그려봅시다.   \n",
    "이를테면, 최대 문장의 길이가 50이고 워드 임베딩 차원을 512로 하는 모델의 입력 벡터 모양이 이와 같을 것입니다.  \n",
    "\n",
    "Q.위의 문장처럼 행의 크기가 50, 열의 크기가 512인 행렬을 만드는 코드를 완성하여 입력 벡터 모양을 시각화하세요.  \n",
    "(추가 : 아래 퀴즈를 풀면서 작성한 코드를 변경해보세요.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e9855e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 행의 크기가 50, 열의 크기가 512인 행렬 생성\n",
    "position = 50\n",
    "d_model = 512\n",
    "sample_pos_encoding = PositionalEncoding(position, d_model)\n",
    "\n",
    "# 시각화\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ba0de5",
   "metadata": {},
   "source": [
    "Q. 임베딩 벡터의 차원이 256이고 최대 문장의 길이가 30인 텍스트를 입력으로 하는 트랜스포머를 구현한다고 하였을 때, 적절한 포지셔널 인코딩 행렬의 크기를 추측해보고 위에 구현한 포지셔널 인코딩 레이어를 사용해 표현해 보세요.  \n",
    "A. 위의 코드에서 50, 512 대신 30, 256을 입력으로 하여 행렬을 만들면 정답입니다. 즉 PositionalEncoding(30,256)로 표현할 수 있습니다.  \n",
    "\n",
    "### 포지셔널 인코딩 - 실제 논문에서 제시된 그림으로 보기\n",
    "![포지셔널 인코딩](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_9_l58gVWT.max-800x600.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7043e7fd",
   "metadata": {},
   "source": [
    "# 4. 어텐션\n",
    "트랜스포머의 인코더와 디코더에서 사용하고 있는 개념인 어텐션에 대해서 알아보겠습니다!\n",
    "\n",
    "## 어텐션이란?\n",
    "어텐션 메커니즘을 그림으로 표현한다면 아래와 같이 표현할 수 있습니다.  \n",
    "![어텐션](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_10_AaCfqrY.png)  \n",
    "\n",
    "### 어텐션 함수는 주어진 '쿼리(Query)'에 대해서 모든 '키(Key)'와의 유사도를 각각 구합니다.\n",
    "- 구해낸 이 유사도를 키(Key)와 맵핑되어있는 각각의 '값(Value)'에 반영해 줍니다. \n",
    "- 유사도가 반영된 '값(Value)'을 모두 더해서 뭉쳐주면 이를 최종 결과인 어텐션 값(Attention Value) 라고 합니다.  \n",
    "\n",
    "## 트랜스포머에서 사용된 어텐션\n",
    "트랜스포머는 총 세 가지의 어텐션을 사용합니다.  \n",
    "![3가지 어텐션](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_11_tFFhFjx.png)  \n",
    "\n",
    "- 첫 번째 그림인 인코더 셀프 어텐션은 인코더에서 이루어지고,\n",
    "- 두 번째 그림인 디코더 셀프 어텐션은 디코더에서 이루어지며,\n",
    "- 세 번째 그림인 인코더-디코더 어텐션 또한 디코더에서 이루어집니다.  \n",
    "\n",
    "![각 어텐션의 위치](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_12_SIe2V15.png)  \n",
    "위 그림은 트랜스포머의 전체적인 아키텍처에서 각 어텐션이 위치한 곳을 보여줍니다.  \n",
    "- 트랜스포머의 어텐션 함수에 사용되는 **쿼리(Query), 키(Key), 밸류(Value) 는 기본적으로 '단어 (정보를 함축한) 벡터'** 입니다.\n",
    "- 단, 여기서 **'단어 벡터' 란 초기 입력으로 사용되었던 임베딩 벡터가 아니고, 트랜스포머의 여러 연산을 거친 후의 단어 벡터** 입니다.\n",
    "\n",
    "### 세 가지 어텐션이 하는 일\n",
    "- 인코더 셀프 어텐션 : 인코더의 입력으로 들어간 문장 내 단어들이 서로 유사도를 구한다.\n",
    "- 디코더 셀프 어텐션 : 단어를 1개씩 생성하는 디코더가 이미 생성된 앞 단어들과의 유사도를 구한다.\n",
    "- 인코더-디코더 어텐션 : 디코더가 잘! 예측하기 위해서 인코더에 입력된 단어들과 유사도를 구한다.    \n",
    "    \n",
    "무려 세 가지 어텐션 중 두 가지가 셀프 어텐션인데요.\n",
    "그럼 대체 셀프 어텐션이 어떤 의미를 가지고 있으며 트랜스포머에서 왜 중요한지 이해해 볼까요?\n",
    "    \n",
    "    \n",
    "## 셀프 어텐션(Self Attention)\n",
    "### 셀프 어텐션이란? 유사도를 구하는 대상이 다른 문장의 단어가 아니라 현재 문장 내의 단어들이 서로 유사도를 구하는 경우\n",
    "가령, 위에서 언급한 인코더-디코더 어텐션은 서로 다른 단어 목록(인코더 내 단어와 디코더 내 단어) 사이에서 유사도를 구하기에 셀프 어텐션이 아닙니다.  \n",
    "![셀프어텐션](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_13_hjMyZwL.png)  \n",
    "https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html  \n",
    "\n",
    "위의 그림은 [구글 AI 블로그 포스트](https://blog.research.google/2017/08/transformer-novel-neural-network.html)에서 가져왔습니다.   \n",
    "위의 예시 문장을 번역하면 '그 동물은 길을 건너지 않았다. 왜냐하면 그것은 너무 피곤하였기 때문이다.' 라는 의미가 됩니다.   \n",
    "그런데 여기서 그것(it) 에 해당하는 것은 과연 길(street) 일까요? 동물(animal) 일까요?  \n",
    "\n",
    "우리는 동물이라는 것을 쉽게 알 수 있지만, 기계는 그렇지 않습니다.   \n",
    "하지만 셀프 어텐션은 입력 문장 내의 단어들끼리 유사도를 구하여 그것(it) 이 동물(animal) 과 연관되었을 확률이 높다는 것을 찾아냅니다.   \n",
    "그런데 한 가지 의문이 듭니다. 유사도는 어떻게 구할까요?\n",
    "\n",
    "Q. 트랜스포머에서 사용되는 어텐션 중 셀프 어텐션을 사용하지 않는 것은 무엇인가요? 그리고 다른 어텐션과 차이점은 무엇인가요?  \n",
    "인코더-디코더 어텐션은 인코더에 입력된 단어들과 디코더에서 생성된 문장의 단어들과의 유사도를 구합니다.   \n",
    "앞에서 나온 번역의 예시인 입력 문장 ‘저는 학생입니다.’와 출력 문장 ‘I am a student’에서 ‘학생’ 단어가 ‘I’, ‘am’, ‘a’, ‘student’ 중 어떤 단어와 유사한지를 계산하는 것 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2f6d73",
   "metadata": {},
   "source": [
    "## 5. 스케일드 닷 프로덕트 어텐션\n",
    "어텐션은 단어들 간의 유사도를 구하는 메커니즘!  \n",
    "- 트랜스포머에서 어텐션 값을 구하는 방법(수식)\n",
    "![attention수식](https://miro.medium.com/max/1400/1*R9Fr5BNs0FroB1b6TStLKQ.webp)  \n",
    "Q, K, V는 각각 쿼리(Query), 키(Key), 값(Value)를 나타냅니다.  \n",
    "\n",
    "앞서 언급했던 어텐션 함수의 정의와 결과값을 다시 상기해봅시다.  \n",
    "어텐션 함수는 주어진 '쿼리(Query)'에 대해서 모든 '키(Key)'와의 유사도를 각각 구합니다.  \n",
    "그리고 구해낸 이 유사도를 키와 맵핑되어있는 각각의 '값(Value)'에 반영해 줍니다.   \n",
    "그리고 유사도가 반영된 '값(Value)'을 모두 더해서 뭉쳐주면 이를 최종 결과인 어텐션 값(Attention Value) 라고 합니다.\n",
    "\n",
    "위 정의와 아래 내용 세 가지만 기억하면 수식을 그림으로 정리할 수 있습니다.  \n",
    "1. Q, K, V는 단어 벡터를 행으로 하는 문장 행렬이다.   \n",
    "    각 단어는 행렬의 한 행에 해당하고(단어 벡터), 여러 단어 벡터들을 조합하여 문장을 나타내는 행렬을 만든다.(문장 행렬)\n",
    "2. 벡터의 내적(dot product) 은 벡터의 유사도를 의미한다.\n",
    "3. 특정 값을 분모로 사용하는 것은 값의 크기를 조절하는 스케일링(Scaling)을 위함이다.  \n",
    "\n",
    "### Q와 K의 전치 행렬을 곱하는 것 - 그림으로 표현\n",
    "![전치 행렬 곱](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_15_pUfIgKn.png)  \n",
    "문장 행렬 Q와 문장 행렬 K를 곱하면 위의 그림과 같은 초록색 행렬을 얻을 수 있습니다.  \n",
    "\n",
    "#### 초록색 행렬이 의미하는 값은? 각 단어 벡터의 유사도가 모두 기록된 유사도 행렬이다!\n",
    "예를 들어 'am' 행과 'student' 열의 값은 Q 행렬에 있던 'am' 벡터와 K 행렬에 있던 'student 벡터'의 내적값을 의미합니다.\n",
    "\n",
    "#### Attintion 값 구하는 방법(과정)\n",
    "- Q와 K의 유사도 구하는 과정\n",
    "    - 위의 유사도 값을 스케일링 해주기 위해서 행렬 전체를 특정 값으로 나눠주고, \n",
    "    - 유사도를 0과 1사이의 값으로 Normalize해주기 위해서 소프트맥스 함수를 사용합니다.  \n",
    "- 여기에 문장 행렬 V와 곱하면 어텐션 값(Attention Value) 를 얻습니다.  \n",
    "![어텐션 값 구하기](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_16_neA52rZ.png)  \n",
    "\n",
    "### 스케일드 닷 프로덕트 어텐션(Scaled Dot Product Attention)\n",
    "![attention수식](https://miro.medium.com/max/1400/1*R9Fr5BNs0FroB1b6TStLKQ.webp)    \n",
    "\n",
    "- 이 수식은 내적(dot product)을 통해 단어 벡터 간 유사도를 구한 후에, 특정 값을 분모로 나눠주는 방식으로 Q와 K의 유사도를 구하였다고 하여 **스케일드 닷 프로덕트 어텐션(Scaled Dot Product Attention)** 이라고 합니다. \n",
    "- 유사도를 구하는 방법이 스케일드 닷 프로덕트(scaled dot product)였기 때문에 이런 이름이 붙은 것!\n",
    "- 만약에 분모에 특정 값을 나눠주는 부분을 사용하지 않았다면 어텐션의 이름은? **닷 프로덕트 어텐션(dot product attention)**  \n",
    "\n",
    "**Q. 특정 값을 분모로 사용하여 스케일링(Scaling)을 하는 이유는?**   \n",
    "A. 스케일링을 하지 않으면 벡터의 내적(dot product) 연산의 결과가 입력 벡터의 차원 수에 따라 크기가 매우 커지게 되고, softmax의 출력값이 작아지는 것을 방지하기 위해서 입니다. softmax의 출력값이 작아지면 역전파 과정에서 기울기 소실 문제가 발생할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6317094f",
   "metadata": {},
   "source": [
    "## 구현하기\n",
    "스케일드 닷 프로덕트 어텐션 함수를 구현해봅니다.  \n",
    "- np.matmul()은 매트릭스, 행렬 곱을 수행하는 메소드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4899ea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # matmul_qk: Query(Q)와 Key(K) 간의 닷 프로덕트를 계산. 이는 어텐션 가중치를 구하기 위한 중간 단계. 어텐션 가중치는 Q와 K의 닷 프로덕트.\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    # logits : 닷 프로덕트를 행렬의 깊이(depth)로 나누어 스케일링을 수행\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가 : mask가 주어졌다면, 어텐션 가중치에 패딩에 대한 마스크를 적용\n",
    "    # 패딩은 어텐션 계산 시 무시되어야 하므로, 해당 위치의 어텐션 가중치를 크게 음의 무한대로 만듭니다.\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용 : Softmax 함수를 사용하여 어텐션 가중치를 계산. 이는 어텐션 가중치를 확률 분포로 만듭니다.\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V(Value)의 닷 프로덕트 -> 이를 통해 쿼리에 대한 어텐션 값을 계산\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2119ecb0",
   "metadata": {},
   "source": [
    "> 코드에서 어텐션 가중치란? [블로그 참조 - 어텐션 분포 구하기 부분](https://moondol-ai.tistory.com/316)  \n",
    "\n",
    "이 글에서 앞으로 어텐션을 수행한다고 한다면, 스케일드 닷 프로덕트 어텐션을 의미합니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181752a2",
   "metadata": {},
   "source": [
    "# 6. 머리가 여러 개인 어텐션\n",
    "![히드라](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_17_l94shVz.png)  \n",
    "그리스 로마 신화에 등장하는 히드라라는 괴물을 아시나요? 머리가 여러 개인 이 괴물은 여러 곳으로 동시에 시선을 둘 수 있었기 때문에 시선의 사각지대가 없어서 처치하기 어려운 괴물입니다. 결국 헤라클레스라는 영웅이 히드라의 머리를 하나씩 제거한 뒤에야 무찌를 수 있었는데요.\n",
    "\n",
    "뜬금없이 갑자기 왜 히드라 얘기냐구요? 다른 비유를 하나 들어볼게요. 굉장히 어려운 문제가 가득한 시험지를 받았을 때 '혼자가 아니라 옆에서 누군가 같이 풀어준다면 좀 더 좋은 성적을 받을 텐데'하고 누구나 한 번쯤 상상해보았을 겁니다.\n",
    "\n",
    "이런 이야기는 현실에서는 상상에 불과하지만, 기계가 할 수 있도록 해줄 수는 있습니다.\n",
    "\n",
    "## 병렬로 어텐션 수행하기\n",
    "트랜스포머에서 **num_heads라는 변수**는 기계가 몇 개의 똑똑한 머리를 사용할지, 다시 말해 **병렬적으로 몇 개의 어텐션 연산을 수행할지를 결정하는 하이퍼파라미터**입니다.\n",
    "![num_heads](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_18_nnOTx9p.png)  \n",
    "\n",
    "앞서 포지셔널 인코딩에서 d_model은 임베딩 벡터의 차원이라고 언급한 바 있습니다.   \n",
    "결국 트랜스포머의 초기 입력인 문장 행렬의 크기는 문장의 길이를 행으로, d_model을 열의 크기로 가집니다.  \n",
    "\n",
    "트랜스포머는 이렇게   \n",
    "- 입력된 문장 행렬을 num_heads의 수만큼 쪼개서 어텐션을 수행하고, \n",
    "- 이렇게 얻은 num_heads의 개수만큼의 어텐션 값 행렬을 다시 하나로 concatenate합니다.  \n",
    "\n",
    "위의 그림은 num_heads가 8개인 경우인데, 다시 concatenate하면서 열의 크기가 d_model이 됩니다.  \n",
    "각자 문제지를 나눠서 푼 후에 마지막에 다시 결과를 합친다고 비유해볼 수도 있겠네요!  \n",
    "\n",
    "Q. 논문에서 d_model은 512의 값을 가졌다고 하고, num_heads는 8의 값을 가졌다고 해요. 그렇다면, 연결하기 전 8개의 어텐션 값(Attention Value) 행렬의 열의 크기는 몇 차원이었을까요?  \n",
    "A. 512/8 = 64  \n",
    "\n",
    "## 멀티-헤드 어텐션\n",
    "### 멀티 헤드 어텐션이란? 어텐션을 병렬로 수행하는 것!\n",
    "이렇게 병렬로 어텐션을 수행하면 얻을 수 있는 효과는 무엇일까요?  \n",
    "![병렬 어텐션](https://d3s0tskafalll9.cloudfront.net/media/original_images/Untitled_19_FwmaA3q.png)   \n",
    "[출처 : http://jalammar.github.io/illustrated-transformer/]  \n",
    "\n",
    "위 그림은 num_heads의 값이 8일 때, **병렬로 수행되는 어텐션이 서로 다른 셀프 어텐션 결과를 얻을 수 있음**을 보여줍니다.   \n",
    "- 다시 말해 8개의 머리는 각각 다른 관점에서 어텐션을 수행하므로 한 번의 어텐션만 수행했다면 놓칠 수도 있던 정보를 캐치할 수 있습니다. \n",
    "- 예를 들어 위 그림에서라면 it_이라는 토큰이 animal_과 유사하다고 보는 관점과 street_과 유사하다고 보는 관점이 한꺼번에 모두 표현 가능하다는 뜻입니다.  \n",
    "\n",
    "### 구현하기\n",
    "멀티 헤드 어텐션을 구현하면 다음과 같습니다.  \n",
    "내부적으로는 스케일드 닷 프로덕트 어텐션 함수를 호출합니다.  \n",
    "\n",
    "Q. 주석을 참고해서 나머지 코드를 완성하세요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad4bb339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 멀티 헤드 어텐션 구현하기\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리(헤드)를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87cb344",
   "metadata": {},
   "source": [
    "**스케일드 닷 프로덕트 어텐션 함수**    \n",
    "이 부분은 Multi-Head Attention에서 각 헤드에서 계산된 어텐션 가중치를 조작하는 부분입니다.  \n",
    "Multi-Head Attention은 여러 헤드에서 각기 다른 어텐션 가중치를 계산하고, 이를 나중에 결합(concatenate)하여 최종 결과를 얻습니다.  \n",
    "\n",
    "여기서 scaled_attention은 scaled_dot_product_attention 함수를 통해 얻어진 어텐션 가중치 행렬입니다.  \n",
    "\n",
    "1. tf.transpose(scaled_attention, perm=[0, 2, 1, 3]):\n",
    "- 어텐션 가중치 행렬의 차원을 조정합니다.\n",
    "- scaled_attention의 형태는 (batch_size, num_heads, sequence_length, depth)이며, 여기서 sequence_length는 입력 시퀀스의 길이, depth는 각 헤드의 차원입니다.\n",
    "- perm=[0, 2, 1, 3]는 차원의 순서를 조정하는데, 두 번째와 세 번째 차원을 서로 바꾸어주어 헤드별로 어텐션 가중치를 정렬합니다.\n",
    "- 결과적으로 어텐션 가중치 행렬의 형태는 (batch_size, sequence_length, num_heads, depth)이 됩니다.\n",
    "\n",
    "2. tf.reshape(scaled_attention, (batch_size, -1, self.d_model)):\n",
    "- tf.reshape를 사용하여 행렬의 형태를 조정합니다.\n",
    "- -1은 해당 차원의 크기를 자동으로 계산하라는 의미입니다. 여기서는 num_heads * depth에 해당하는 값이 됩니다.\n",
    "- 결과적으로 최종 어텐션 가중치의 형태는 (batch_size, sequence_length, d_model)이 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf5ec2",
   "metadata": {},
   "source": [
    "# 7. 마스킹\n",
    "마스킹(Masking) 이란, 특정 값들을 가려서 실제 연산에 방해가 되지 않도록 하는 기법입니다.  \n",
    "트랜스포머에서는 어텐션을 위해서 크게 두 가지 마스킹을 사용합니다.  \n",
    "\n",
    "## 패딩 마스킹(Padding Masking)\n",
    "첫 번째 마스킹은 패딩 토큰(Padding token)을 이용한 방법입니다.  \n",
    "자연어 처리에서 패딩(Padding)이란 어떤 개념일까요?  \n",
    "![패딩](https://d3s0tskafalll9.cloudfront.net/media/images/1365906-20200410103623697-871078599.max-800x600.png)  \n",
    "패딩은 문장의 길이가 서로 다를 때, 모든 문장의 길이를 동일하게 해주는 과정에서 정해준 길이보다 짧은 문장의 경우에는 숫자 0을 채워서 문장의 길이를 맞춰주는 자연어 처리 전처리 방법입니다.  \n",
    "위 그림은 케라스의 pad_sequences()를 사용하여 패딩을 하는 과정을 시각화한 그림입니다.  \n",
    "\n",
    "그런데 사실 이렇게 주어진 숫자 0은 실제 의미가 있는 단어가 아니므로 실제 어텐션 등과 같은 연산에서는 제외할 필요가 있습니다.   \n",
    "패딩 마스킹은 이를 위해 숫자 0인 위치를 체크합니다.  \n",
    "\n",
    "다음은 패딩 마스킹을 구현한 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e7ee2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 패딩 마스킹 함수 구현\n",
    "\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(\"슝=3\")\n",
    "\n",
    "# tf.math.equal(x, 0) : 입력 x에서 값이 0인 위치를 찾아 True로 표시한 불리언 텐서를 생성합니다. 이는 패딩 토큰에 해당하는 위치를 나타냅니다.\n",
    "# tf.cast(..., tf.float32) : \n",
    "# 불리언 텐서를 0 또는 1의 값을 가지는 실수형 텐서로 변환. 따라서 패딩 토큰의 위치는 1의 값을 가지고, 나머지 위치는 0의 값을 가지게 됩니다.\n",
    "# mask[:, tf.newaxis, tf.newaxis, :]:\n",
    "# 마스크 텐서의 차원을 확장합니다. tf.newaxis를 사용하여 새로운 축을 추가하고, 이를 통해 적절한 차원을 맞춥니다.\n",
    "# 최종적으로 반환되는 패딩 마스크의 형태는 (batch_size, 1, 1, sequence_length)가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abecc4cd",
   "metadata": {},
   "source": [
    "이 함수에 정수 시퀀스를 입력으로 하면, 이 함수는 숫자가 0인 부분을 체크한 벡터를 리턴합니다.  \n",
    "(이 함수를 호출하면 입력 시퀀스에서 패딩 토큰에 해당하는 위치를 가리키는 패딩 마스크가 생성되어 반환됩니다.   \n",
    "이 마스크는 어텐션 연산에서 패딩 토큰의 영향을 배제하는 데 사용됩니다.)     \n",
    "\n",
    "두 개의 정수 시퀀스를 입력으로 해보고, 각각 어떤 결과가 나오는지 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "003e048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 2개의 정수 시퀀스 입력해보기\n",
    "\n",
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95e8420",
   "metadata": {},
   "source": [
    "두 정수 시퀀스에 대해서 각각 결과가 출력되는데, 오직 숫자가 0인 위치에서만 숫자 1이 나오고 숫자 0이 아닌 위치에서는 숫자 0인 벡터를 출력합니다.  \n",
    "어텐션 연산 시에 패딩 마스킹을 참고하면 불필요하게 숫자 0을 참고하지 않게 할 수 있겠죠?  \n",
    "\n",
    "## 룩 어헤드 마스킹(Look-ahead masking, 다음 단어 가리기)\n",
    "순환 신경망, RNN과 트랜스포머는 문장을 입력받을 때 입력받는 방법이 전혀 다릅니다.\n",
    "- RNN은 step이라는 개념이 존재해서 각 step마다 단어가 순서대로 입력으로 들어가는 구조인 반면 \n",
    "- 트랜스포머의 경우에는 문장 행렬을 만들어 한 번에 행렬 형태로 입력으로 들어간다는 특징이 있습니다.   \n",
    "그리고 이 특징 때문에 추가적인 마스킹(Masking) 을 필요합니다.  \n",
    "\n",
    "### RNN\n",
    "RNN으로 다음 단어를 예측해가면서 문장을 생성해내는 과정을 보겠습니다.  \n",
    "다시 말해 RNN으로 디코더를 구현했을 경우입니다.  \n",
    "![RNN decoder](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_20_NAntZnv.max-800x600.png)  \n",
    "http://torch.ch/blog/2016/07/25/nce.html  \n",
    "\n",
    "RNN은 구조상으로 다음 단어를 만들어 갈 때, 자신보다 앞에 있는 단어들만 참고해서 다음 단어를 예측합니다.   \n",
    "위의 그림을 참고로 각 단계에서 다음 단어 예측 과정을 서술하면 다음과 같습니다.\n",
    "- 첫 번째 step  \n",
    "현재까지의 입력 : what → 출력 : is\n",
    "- 두 번째 step  \n",
    "현재까지의 입력 : what is → 출력 : the\n",
    "- 세 번째 step  \n",
    "현재까지의 입력 : what is the → 출력 problem  \n",
    "\n",
    "### 트랜스포머\n",
    "하지만 트랜스포머의 경우, 전체 문장이 문장 행렬로 들어가기 때문에 위치와 상관없이 모든 단어를 참고해서 다음 단어를 예측할 수 있습니다.   \n",
    "하지만 사실 우리가 원하는 것은 이전 단어들로부터 다음 단어를 예측하는 훈련을 제대로 하는 것입니다.   \n",
    "따라서 이러한 문제를 해결하기 위해 자신보다 다음에 나올 단어를 참고하지 않도록 가리는 기법이 룩 어헤드 마스킹 기법입니다.  \n",
    "\n",
    "이 기법은 어텐션을 수행할 때, Query 단어 뒤에 나오는 Key 단어들에 대해서는 마스킹 합니다.  \n",
    "![transformer decoder](https://d3s0tskafalll9.cloudfront.net/media/images/_.max-800x600.png)  \n",
    "https://www.youtube.com/watch?v=xhY7m8QVKjo  \n",
    "\n",
    "위의 그림에서 빨간색으로 색칠된 부분은 마스킹을 표현하고 있습니다.   \n",
    "빨간색은 실제 어텐션 연산에서 가리는 역할을 하여 어텐션 연산 시에 현재 단어를 기준으로 이전 단어들하고만 유사도를 구할 수 있습니다.   \n",
    "행을 Query, 열을 Key로 표현된 행렬임을 감안하고 천천히 행렬을 살펴봅시다.\n",
    "\n",
    "예를 들어 Query 단어가 '찾고'라고 한다면, 이 '찾고'라는 행에는 '< s >, 나는, 행복을, 찾고' 까지의 열만 보이고 그 뒤 열은 아예 빨간색으로 칠해져 있습니다.  \n",
    "즉, 유사도를 구할 수 없도록 해놓았습니다. 저 빨간색 부분을 마스킹 함수로 구현하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8eb9e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# look-ahead masking 함수 구현 (빨강색 부분 = 다음 단어 가리기)\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "    # 입력 x의 시퀀스 길이를 구합니다. 즉, 시퀀스의 두 번째 차원의 크기를 가져와서 seq_len 변수에 저장합니다.\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(\"슝=3\")\n",
    "\n",
    "\n",
    "# look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0):\n",
    "# tf.ones((seq_len, seq_len))를 사용하여 모든 원소가 1인 행렬을 만듭니다.\n",
    "# tf.linalg.band_part(..., -1, 0)를 사용하여 행렬의 아래 삼각행렬을 0으로 만들고, 위 삼각행렬은 1로 남깁니다.\n",
    "# 1 - ...를 통해 원래의 위 삼각행렬이 0이 되고, 아래 삼각행렬이 1이 되도록 합니다. 이것이 룩 어헤드 마스크입니다.\n",
    "\n",
    "# padding_mask = create_padding_mask(x): 앞서 정의한 create_padding_mask 함수를 사용하여 패딩 마스크를 생성합니다.\n",
    "\n",
    "# tf.maximum(look_ahead_mask, padding_mask):\n",
    "# 룩 어헤드 마스크와 패딩 마스크 중에서 더 큰 값을 선택합니다. \n",
    "# 이는 룩 어헤드 마스크와 패딩 마스크 중에서 더 큰 영향을 주는 위치를 선택하는 것으로, 어텐션 연산에서 사용될 마스크를 결정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30e5e493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 직접 입력을 넣어 테스트 해보기\n",
    "\n",
    "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51f15ac",
   "metadata": {},
   "source": [
    "대각선의 형태로 숫자 1이 채워지는 것을 볼 수 있습니다.   \n",
    "그런데 이 마스킹과 패딩 마스킹은 별개이므로, 이 마스킹을 수행할 때 만약에 숫자 0인 단어가 있다면 이 또한 패딩 해야 합니다.   \n",
    "그래서 create_look_ahead_mask() 함수는 내부적으로 앞서 구현한 패딩 마스크 함수도 호출하고 있습니다.  \n",
    "\n",
    "> shape=(1, 1, 5, 5)의 의미  \n",
    "> - 첫 번째 차원 (1):  \n",
    "이 차원은 배치 크기(batch size)를 나타냅니다. 현재는 1로 설정되어 있어서 하나의 시퀀스만 처리하고 있다는 것을 의미합니다.\n",
    "> - 두 번째 차원 (1):  \n",
    "이 차원은 헤드(heads)의 수를 나타냅니다. Multi-Head Attention에서는 여러 헤드를 사용하여 어텐션을 계산할 수 있습니다. 현재는 1로 설정되어 있으므로 하나의 헤드만 사용한다는 것을 의미합니다.\n",
    "> - 세 번째 차원 (5):  \n",
    "이 차원은 시퀀스 길이(sequence length)를 나타냅니다. 입력 시퀀스의 길이가 5이므로 이 차원의 크기는 5입니다.\n",
    "> - 네 번째 차원 (5):  \n",
    "이 차원 역시 시퀀스 길이(sequence length)를 나타냅니다. 룩 어헤드 마스크는 현재 위치 이후의 토큰에 대한 어텐션을 막기 위한 것이므로, 현재 위치부터 시퀀스의 끝까지를 나타내는 차원입니다.\n",
    "\n",
    "숫자 0이 포함되었을 경우에도 테스트해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29c125fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1. 1. 1. 1. 1.]\n",
      "   [1. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 1.]\n",
      "   [1. 0. 0. 0. 1.]\n",
      "   [1. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 숫자 0이 포함된 경우 테스트 해보기\n",
    "\n",
    "print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ee9b48",
   "metadata": {},
   "source": [
    "# 8. 인코더\n",
    "트랜스포머의 입력, 그리고 트랜스포머 내부에서 일어나는 어텐션에 대해서도 간단히 정리해봤습니다. 이제 트랜스포머의 인코더를 설계해 보겠습니다.\n",
    "\n",
    "## 인코더 층 만들기\n",
    "![인코더 층](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_21_Y7Cy8sm.max-800x600.png)  \n",
    "[출처 : http://jalammar.github.io/illustrated-transformer/]  \n",
    "\n",
    "하나의 인코더 층은 크게 총 2개의 서브 층(sublayer)으로 나누어집니다.  \n",
    "- 인코더 층 = 셀프 어텐션 + 피드 포워드 신경망  \n",
    "- 셀프 어텐션은 멀티 헤드 어텐션으로 병렬적으로 이루어집니다.\n",
    "\n",
    "두 개의 서브 층을 가지는 하나의 인코더 층을 구현하는 함수는 다음과 같습니다. 함수 내부적으로 첫 번째 서브 층과 두 번째 서브 층을 구현하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d5918e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")   \n",
    "    # shape=(배치 사이즈, 헤드의 수, 시퀀스 길이)\n",
    "    # 시퀀스의 길이 = None : 입력 시퀀스의 길이에 따라 동적으로 조정될 수 있다는 의미\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행 (어텐션의 결과는 드롭아웃과 레이어 정규화를 거친다.)\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57a9653",
   "metadata": {},
   "source": [
    "![인코더](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_22_teJgoCi.max-800x600.png)  \n",
    "[출처 : http://jalammar.github.io/illustrated-transformer/]  \n",
    "\n",
    "## 인코더 층을 쌓아 인코더 만들기\n",
    "이렇게 구현한 인코더 층을 임베딩 층(Embedding layer)과 포지셔널 인코딩(Positional Encoding)을 연결하고,   \n",
    "사용자가 원하는 만큼 인코더 층을 쌓음으로써 트랜스포머의 인코더가 완성됩니다.  \n",
    "\n",
    "인코더와 디코더 내부에서는 각 서브 층 이후에 훈련을 돕는 Layer Normalization이라는 테크닉이 사용되었습니다.   \n",
    "위 그림에서는 Normalize라고 표시된 부분에 해당됩니다.  \n",
    "\n",
    "트랜스포머는 하이퍼파라미터인 num_layers 개수의 인코더 층을 쌓습니다.   \n",
    "논문에서는 총 6개의 인코더 층을 사용하였지만, 실습에서는 학습 시간을 고려하여 그보다 적은 개수를 사용할 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "723035ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 구현\n",
    "\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")   # inputs: 모델의 입력으로서 단어 인덱스들을 나타냅니다.\n",
    "\n",
    "  # 패딩 마스크 사용 (encoder_layer 함수에서 사용됨)\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)   # 단어 인덱스들을 임베딩하여 단어 벡터를 생성\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))   # 임베딩 차원에 루트를 씌워줌으로써 스케일 조정을 수행합니다.\n",
    "\n",
    "  # 포지셔널 인코딩 : 임베딩 된 단어 벡터에 포지셔널 인코딩 처리 (입력 시퀀스의 각 단어 위치에 대한 상대적인 정보를 주입하는 역할)\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)  # 드롭아웃을 적용하여 모델의 일반화 능력을 향상시킴\n",
    "\n",
    "  # 여러 개의 인코더 레이어 쌓기 : num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4497e3cb",
   "metadata": {},
   "source": [
    "**def encoder 인자 뜯어보기**   \n",
    "\n",
    "- vocab_size : 모델이 다루는 어휘 집합(Vocabulary size)의 크기를 나타냅니다. \n",
    "    - 어휘 집합은 모델이 이해하고 다루는 단어나 토큰들의 총 개수를 말합니다.\n",
    "    - 트랜스포머 모델은 입력으로 어휘 집합의 각 단어를 나타내는 정수 인덱스를 받습니다. vocab_size는 이러한 정수 인덱스의 범위를 나타냅니다.\n",
    "    - 예를 들어, 만약 어휘 집합에 10,000개의 고유한 단어가 있다면 vocab_size는 10,000이 됩니다.\n",
    "    - 일반적으로 어휘 집합의 크기는 자주 등장하는 단어를 포함할 수 있도록 설정됩니다.  \n",
    "      이 값은 모델의 입력 임베딩 레이어의 크기 및 학습 가능한 파라미터의 수에 영향을 미치게 됩니다.  \n",
    "      \n",
    "    \n",
    "- num_layers : 트랜스포머 모델의 인코더나 디코더에서 사용되는 레이어의 개수\n",
    "    - 일반적으로 모델의 용량(capacity)을 늘리려면 레이어의 수를 늘리고, 그에 따라 학습할 수 있는 특징의 수가 증가합니다.\n",
    "    - num_layers=6으로 설정하면 인코더나 디코더에서 각각 6개의 레이어를 쌓게 됩니다. \n",
    "    - 이 값은 주로 모델의 복잡성과 데이터의 특성에 따라 조절되며, 실험과 검증을 통해 최적의 값을 찾게 됩니다.\n",
    "    \n",
    "    \n",
    "- units : 트랜스포머의 인코더 레이어나 디코더 레이어에서 사용되는 완전연결층(fully connected layer)의 출력 차원\n",
    "    - 해당 레이어의 유닛 수를 결정하는 매개변수로, 모델의 용량(capacity)에 영향을 미칩니다.\n",
    "    - 보통 units의 값은 트랜스포머의 차원인 d_model과 관련이 있습니다.   \n",
    "    예를 들어, units=d_model*4와 같이 설정될 수 있습니다.   \n",
    "    하지만 이는 일반적인 규칙은 아니며, 모델의 구조나 작업에 따라 최적의 값이 달라질 수 있습니다. \n",
    "    \n",
    "    \n",
    "- d_model : 트랜스포머 모델에서 사용되는 임베딩 벡터의 차원(또는 특징의 차원)\n",
    "    - 모델 내부에서 다양한 연산이 이루어지는 벡터의 차원으로, 트랜스포머의 핵심 파라미터 중 하나입니다.\n",
    "    - 트랜스포머의 인코더와 디코더에서는 입력된 단어의 임베딩이 d_model 차원을 갖도록 설계됩니다. \n",
    "    - 이 차원은 어텐션 메커니즘, 피드포워드 네트워크 등 다양한 연산에 적용되며, 모델의 용량(capacity)을 결정하는 중요한 요소 중 하나입니다.\n",
    "    - 일반적으로 d_model은 트랜스포머의 하이퍼파라미터 중 하나로 설정되며, 주로 256, 512, 1024 등의 값이 사용됩니다. \n",
    "    - 적절한 d_model의 선택은 모델의 학습과 일반화 성능에 영향을 미칩니다.\n",
    "    \n",
    "    \n",
    "- num_heads : \n",
    "    - 트랜스포머의 어텐션 메커니즘은 여러 헤드로 나누어져 병렬로 계산되고, 각 헤드의 출력이 합쳐져 최종 출력이 생성됩니다.    \n",
    "    이렇게 함으로써 모델은 각 헤드가 서로 다른 측면에 집중하도록 학습하게 되어 다양한 특징을 추출할 수 있습니다.   \n",
    "    - 일반적으로 num_heads는 8 또는 12와 같은 값으로 설정됩니다. \n",
    "    - 적절한 num_heads의 선택은 모델의 성능과 효율성(계산 비용 대비 더 많은 병렬 계산 수행)에 영향을 미치므로 조심스럽게 결정되어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0675575",
   "metadata": {},
   "source": [
    "# 9. 디코더\n",
    "디코더는 인코더와 비슷하지만, 인코더보다 조금 더 복잡합니다.   \n",
    "**인코더는 두 개의 서브 층으로 구성되지만, 디코더는 세 개의 서브 층으로 구성**된다는 점이 다릅니다.  \n",
    "\n",
    "## 디코더 층\n",
    "![디코더 층](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_23_vBHZ3i0.max-800x600.png)  \n",
    "[출처 : http://jalammar.github.io/illustrated-transformer/]  \n",
    "\n",
    "첫 번째는 셀프 어텐션, 두 번째는 인코더-디코더 어텐션, 세 번째는 피드 포워드 신경망입니다.   \n",
    "인코더-디코더 어텐션은 셀프 어텐션과는 달리,   \n",
    "- Query가 디코더의 벡터인 반면에 Key와 Value가 인코더의 벡터라는 특징이 있습니다. \n",
    "- 이 부분이 인코더가 입력 문장으로부터 정보를 디코더에 전달하는 과정입니다.  \n",
    "\n",
    "\n",
    "![디코더 스케일드 닷 프로덕트 어텐션](https://d3s0tskafalll9.cloudfront.net/media/images/Untitled_24_Kj9egLY.max-800x600.png)  \n",
    "[출처 : https://medium.com/@shreyasikalra25/predict-movie-reviews-with-bert-88d8b79f5718]  \n",
    "\n",
    "인코더의 셀프 어텐션과 마찬가지로 디코더의 셀프 어텐션, 인코더-디코더 어텐션 두 개의 어텐션 모두 스케일드 닷 프로덕트 어텐션을 멀티 헤드 어텐션으로 병렬적으로 수행합니다.\n",
    "\n",
    "디코더의 세 개의 서브 층을 내부적으로 구현한 디코더의 함수는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1d41edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    # inputs: 현재 디코더 레이어의 입력으로 들어가는 시퀀스.\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    # enc_outputs: 인코더의 출력. 디코더는 이를 참조하여 인코더-디코더 어텐션을 수행.\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    # look_ahead_mask: 디코더 셀프 어텐션에서 사용되는 마스크. 현재 위치 이후의 토큰에 대한 정보를 가립니다.\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    # padding_mask: 패딩을 처리하기 위한 마스크. 패딩 토큰에 대한 어텐션을 제한합니다.\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    # 이는 현재 위치의 단어에 주목하면서 인코더의 다른 단어들 간의 관계를 고려합니다.\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    # 디코더가 인코더의 출력을 참조하여 현재 위치의 단어와 인코더의 단어 간의 관계를 고려합니다.\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층을 거쳐 최종 출력을 얻습니다.\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4c26bd",
   "metadata": {},
   "source": [
    "> **look_ahead_mask의 shape이 (1, None, None)인 이유는?**  \n",
    "셀프 어텐션(Self-Attention)에서 현재 위치 이후의 단어들에 대한 마스크를 적용하기 위함입니다.  \n",
    "\n",
    "> - 첫 번째 차원인 1: 디코더의 현재 위치에 대한 어텐션을 수행하기 때문에 배치 차원은 1입니다.\n",
    "> - 두 번째 차원인 None: 현재 위치 이후의 단어들과의 어텐션에 대한 마스크를 나타냅니다. 이 차원은 시퀀스의 길이에 따라 유동적으로 조절됩니다. 현재 위치 이후의 단어들에 대해 어텐션을 수행하므로 이 차원은 현재 위치 이후의 토큰 수에 해당하는 값이 됩니다.\n",
    "> - 세 번째 차원인 None: 각 위치별로 서로 다른 마스크를 적용하기 위해 사용됩니다. 이 차원은 현재 위치 이후의 모든 단어들에 대해 서로 다른 마스크를 적용하기 위한 것입니다.  \n",
    "\n",
    "> 따라서, look_ahead_mask는 현재 위치 이후의 단어들 간의 관계를 고려할 때 사용되며, 셀프 어텐션에서 현재 위치 이후의 단어들에 대한 정보를 가립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e1614",
   "metadata": {},
   "source": [
    "## 디코더 층을 쌓아 디코더 만들기\n",
    "이렇게 구현한 디코더의 층은 임베딩 층(Embedding layer) 과 포지셔널 인코딩(Positional Encoding) 을 연결하고,   \n",
    "사용자가 원하는 만큼 디코더 층을 쌓아 트랜스포머의 디코더가 완성됩니다.\n",
    "\n",
    "인코더와 마찬가지로 num_layers 개수의 디코더 층을 쌓습니다.   \n",
    "논문에서는 총 6개의 디코더 층을 사용하였지만, 실습에서는 학습 시간을 고려하여 그보다 적은 개수를 사용할 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ad4fef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 구현\n",
    "\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')   # inputs: 디코더의 입력으로 들어가는 시퀀스.\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')   # enc_outputs: 인코더의 출력. 디코더는 이를 참조하여 인코더-디코더 어텐션을 수행.\n",
    "    # look_ahead_mask: 디코더의 셀프 어텐션에서 사용되는 마스크. 현재 위치 이후의 토큰에 대한 정보를 가립니다.\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크 : 패딩을 처리하기 위한 마스크. 패딩 토큰에 대한 어텐션을 제한합니다.\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)   # 입력 시퀀스를 임베딩 레이어를 통해 임베딩\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))   # 스케일을 조절\n",
    "\n",
    "  # 포지셔널 인코딩 : 단어의 위치 정보를 추가\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행 : 과적합 방지를 위해 일부 토큰을 랜덤하게 제거\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 디코더 레이어 쌓기 (num_layers 개수만큼)\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "    # 디코더 레이어의 입력은 이전 레이어의 출력인 outputs와 함께 인코더의 출력(enc_outputs), 셀프 어텐션 마스크(look_ahead_mask), 패딩 마스크(padding_mask)를 받습니다.\n",
    "\n",
    "    # 입력과 출력을 정의한 후, 해당 디코더 모델을 반환\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377dcc8b",
   "metadata": {},
   "source": [
    "이제 인코더 층과 디코더 층을 각각 함수로 구현하였습니다.  \n",
    "\n",
    "이를 하나로 조합하여 트랜스포머 모델을 만들 수 있을 텐데, 우선 그전에 여기서 사용할 챗봇 데이터를 로드하고, 전처리해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad97c1",
   "metadata": {},
   "source": [
    "# 10. 챗봇의 병렬 데이터 받아오기\n",
    "- 사용할 데이터셋 : Cornell Movie-Dialogs Corpus라는 영화 및 TV 프로그램에서 사용되었던 대화의 쌍으로 구성된 데이터셋\n",
    "    - 대화의 쌍이라고 하는 것은 기본적으로 먼저 말하는 사람의 대화 문장이 있고, 그에 응답하는 대화 문장의 쌍으로 이루어집니다.\n",
    "    \n",
    "- 데이터를 받아오는 이번 스텝에서 목표로 하는 것은 다음과 같습니다.\n",
    "1. 정해진 개수인 50,000개의 질문과 답변의 쌍을 추출한다.\n",
    "2. 문장에서 단어와 구두점 사이에 공백을 추가한다.\n",
    "3. 알파벳과 ! ? , . 이 4개의 구두점을 제외하고 다른 특수문자는 모두 제거한다.  \n",
    "\n",
    "## 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03e40664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 데이터 다운로드\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'cornell_movie_dialogs.zip',\n",
    "    origin='http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_dataset = os.path.join(\n",
    "    os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\")\n",
    "\n",
    "path_to_movie_lines = os.path.join(path_to_dataset, 'movie_lines.txt')\n",
    "path_to_movie_conversations = os.path.join(path_to_dataset,'movie_conversations.txt')\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f79c6e",
   "metadata": {},
   "source": [
    "> **데이터 다운로드 코드 주석**  \n",
    "> - get_file 함수를 사용하여 대화 말뭉치 압축 파일을 다운로드하고 압축을 해제합니다.\n",
    "> - 다운로드한 파일은 path_to_zip에 저장되고, 압축 해제된 데이터셋은 path_to_dataset 디렉토리에 저장됩니다.\n",
    "> - 대화 말뭉치에는 대화의 문장이 담긴 movie_lines.txt와 대화의 흐름을 나타내는 movie_conversations.txt 두 가지 파일이 있습니다.\n",
    "> - path_to_movie_lines와 path_to_movie_conversations는 각각 movie_lines.txt와 movie_conversations.txt 파일의 경로를 나타냅니다.\n",
    "\n",
    "여기서 우리가 사용할 데이터는 실습 시간을 고려하여 전체 데이터 중 일부입니다.   \n",
    "우선, 데이터 중에서 5만 개만 가져오도록 하고 질문과 답변의 쌍의 형태로 데이터셋을 가공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbb8dcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "\n",
    "MAX_SAMPLES = 50000\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c83b6",
   "metadata": {},
   "source": [
    "이를 위한 전처리 함수는 다음과 같습니다.  \n",
    "이번 전처리는 정규 표현식(Regular Expression) 을 사용하여 구두점(punctuation) 을 제거하여 단어를 토크나이징(tokenizing) 하는 일에 방해가 되지 않도록 정제하는 것을 목표로 합니다.  \n",
    "\n",
    "Q.주석을 참고해서 전처리하는 함수를 완성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f176944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 전처리 함수\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "  # 입력받은 sentence를 소문자로 변경하고 양쪽 공백을 제거\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2ece8f",
   "metadata": {},
   "source": [
    "**전처리 함수 주석**  \n",
    "- 단어와 구두점 사이의 거리 만들기\n",
    "    - re.sub(r\"([?.!,])\", r\" \\1 \", sentence): 이 정규표현식은 문장에서 ?, ., !, ,와 같은 구두점 앞뒤에 공백을 추가합니다.   \n",
    "        여기서 ([?.!,])는 괄호 안에 속하는 문자 중 하나와 일치하고, r\" \\1 \"은 매칭된 문자를 그룹화하고 해당 문자 앞뒤에 공백을 추가합니다.  \n",
    "        \\1은 그룹화된 첫 번째 부분과 일치하는 문자를 나타냅니다.\n",
    "\n",
    "    - re.sub(r'[\" \"]+', \" \", sentence): 이 정규표현식은 여러 개의 공백을 하나의 공백으로 대체합니다.   \n",
    "        [\" \"]+는 하나 이상의 공백을 의미하며, 이를 \" \"로 대체하여 여러 개의 공백을 하나의 공백으로 줄입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce73e06",
   "metadata": {},
   "source": [
    "### 질문과 답변의 쌍을 전처리\n",
    "데이터를 로드하는 동시에 전처리 함수를 호출하여 질문과 답변의 쌍을 전처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cae09505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "\n",
    "def load_conversations():\n",
    "  id2line = {}\n",
    "  with open(path_to_movie_lines, errors='ignore') as file:\n",
    "    lines = file.readlines()\n",
    "  for line in lines:\n",
    "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "    id2line[parts[0]] = parts[4]\n",
    "\n",
    "  inputs, outputs = [], []\n",
    "  with open(path_to_movie_conversations, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "  for line in lines:\n",
    "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "    conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
    "\n",
    "    for i in range(len(conversation) - 1):\n",
    "      # 전처리 함수를 질문에 해당되는 inputs(conversation[i])와 답변에 해당되는 outputs(conversation[i + 1])에 적용.\n",
    "      inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
    "      outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
    "\n",
    "    # inputs 리스트에 쌓이는 데이터 샘플의 수가 MAX_SAMPLES 이상이 되면, 더 이상의 데이터를 읽지 않고 현재까지 쌓인 inputs와 outputs를 반환하라\n",
    "      if len(inputs) >= MAX_SAMPLES:\n",
    "        return inputs, outputs\n",
    "  return inputs, outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03471ab",
   "metadata": {},
   "source": [
    "**함수 주석**  \n",
    "- id2line 딕셔너리 생성:\n",
    "    - path_to_movie_lines에 있는 'movie_lines.txt' 파일을 열어 각 라인에서 대화의 ID와 해당하는 대화 문장을 추출하여 id2line 딕셔너리에 저장합니다.\n",
    "- with 부분\n",
    "    - movie_lines.txt' 파일을 열어서 그 내용을 읽어온 후, 각 라인을 리스트로 저장하는 코드입니다.\n",
    "    - with open(path_to_movie_lines, errors='ignore') as file:: 'movie_lines.txt' 파일을 열고, 파일 내용을 읽어오는데 사용할 파일 핸들을 file 변수에 할당합니다.   \n",
    "            errors='ignore'는 인코딩 오류가 발생할 경우 무시하도록 하는 옵션입니다. \n",
    "    - lines = file.readlines(): 파일 핸들인 file에서 readlines 메서드를 사용하여 파일의 각 라인을 읽어와서 리스트 lines에 저장합니다.   \n",
    "        리스트의 각 요소는 파일의 한 라인에 해당합니다.\n",
    "    - line.replace('\\n', ''): line 문자열에서 개행 문자(\\n)를 공백으로 대체합니다. 이렇게 하면 각 라인의 끝에 있는 개행 문자를 제거할 수 있습니다.\n",
    "    - .split(' +++$+++ '): 문자열을 +++$+++를 구분자로 사용하여 나눕니다. 이렇게 하면 대화의 여러 부분이 리스트 parts에 저장됩니다.  \n",
    "\n",
    "최종적으로 parts 리스트에는 대화의 여러 부분이 포함되어 있습니다.   \n",
    "이 중에서 parts[0]은 대화 ID를 나타내고, parts[4]는 해당 대화의 문장을 나타냅니다.   \n",
    "\n",
    "\n",
    "- with open(path_to_movie_conversations, 'r') as file: 여기서 'r'은 읽기 모드  \n",
    "\n",
    "\n",
    "- conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
    "    - parts[3][1:-1].split(', '): parts[3]은 대화 ID들이 저장된 부분입니다.   \n",
    "      이 부분은 대괄호로 둘러싸여 있고 쉼표로 구분된 문자열입니다. 대괄호를 제거하고 쉼표로 나누기 위해 [1:-1].split(', ')를 사용합니다.\n",
    "        - [1:-1]: 대화 ID들을 감싸는 대괄호를 제거하기 위해 첫 번째 문자부터 마지막 문자 전까지 선택합니다.\n",
    "        - .split(', '): 쉼표와 공백을 기준으로 문자열을 나눠 리스트로 만듭니다.\n",
    "        \n",
    "        \n",
    "- [line[1:-1] for line in ...]: 각 대화 ID에 대해 대괄호를 제거하고 리스트에 추가합니다. 이를 리스트 내포로 구현했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42aaf61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 50000\n",
      "전체 샘플 수 : 50000\n"
     ]
    }
   ],
   "source": [
    "# 로드한 데이터의 샘플 수 확인하기\n",
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "\n",
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c28859",
   "metadata": {},
   "source": [
    "질문과 답변은 병렬적으로 구성되는 데이터셋이므로 두 샘플 수는 정확하게 일치해야 합니다.  \n",
    "둘 다 5만 개의 샘플이 저장되었습니다.  \n",
    "\n",
    "임의로 22번째 샘플(인덱스 상으로는 21번 샘플)을 출력해서 질문과 답변이 병렬적으로 잘 저장은 되었는지, 그리고 전처리 함수에서 의도했던 전처리가 진행되었는지 확인해 봅시다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22e10b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: she s not a . . .\n",
      "전처리 후의 22번째 답변 샘플: lesbian ? no . i found a picture of jared leto in one of her drawers , so i m pretty sure she s not harboring same sex tendencies .\n"
     ]
    }
   ],
   "source": [
    "# 전처리가 잘 되었는지 테스트 \n",
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f12d50",
   "metadata": {},
   "source": [
    "?나 .과 같은 구두점들이 단어들과 분리되어 단어와 구두점 사이에는 공백이 추가된 것을 확인할 수 있습니다.   \n",
    "이렇게 함으로써 단어를 토크나이징 하는 과정에서 구두점과 붙어있던 단어들을 하나의 단어로 인식하는 것을 방지할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a7d3f3",
   "metadata": {},
   "source": [
    "# 11. 병렬 데이터 전처리하기\n",
    "질문과 답변의 셋을 각각 questions와 answers에 저장하였으므로, 본격적으로 전처리를 진행해보겠습니다.   \n",
    "이번 스텝에서 진행할 전체적인 과정을 요약하면 다음과 같습니다.\n",
    "\n",
    "1. TensorFlow Datasets SubwordTextEncoder 를 토크나이저로 사용한다.    \n",
    "단어보다 더 작은 단위인 Subword를 기준으로 토크나이징하고,  각 토큰을 고유한 정수로 인코딩 한다.  \n",
    "2. 각 문장을 토큰화하고 각 문장의 시작과 끝을 나타내는 START_TOKEN 및 END_TOKEN을 추가한다.  \n",
    "3. 최대 길이 MAX_LENGTH 인 40을 넘는 문장들은 필터링한다.\n",
    "4. MAX_LENGTH보다 길이가 짧은 문장들은 40에 맞도록 패딩 한다.  \n",
    "\n",
    "## 1. 단어장(Vocabulary) 만들기\n",
    "우선 각 단어에 고유한 정수 인덱스를 부여하기 위해서 단어장(Vocabulary)을 만들어보겠습니다.  \n",
    "단어장을 만들 때는 질문과 답변 데이터셋을 모두 사용하여 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b7a90f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\n",
      "슝=3 \n"
     ]
    }
   ],
   "source": [
    "# 단어장 만들기 \n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "print(\"살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\")\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "print(\"슝=3 \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b568cc6",
   "metadata": {},
   "source": [
    "### 시작 토큰, 종료 토큰에 고유한 정수 부여\n",
    "이때 디코더의 문장 생성 과정에서 사용할 '시작 토큰'과 '종료 토큰'에 대해서도 임의로 단어장에 추가하여서 정수를 부여해 줍니다.    \n",
    "이미 생성된 단어장의 번호와 겹치지 않도록 각각 단어장의 크기와 그보다 1이 큰 수를 번호로 부여하면 되겠죠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f082e30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce2cca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8331]\n",
      "END_TOKEN의 번호 : [8332]\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 부여된 정수 출력해보기 \n",
    "\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4004619",
   "metadata": {},
   "source": [
    "각각 8,331과 8,332라는 점에서 현재 단어장의 크기가 8,331(0번부터 8,330번)이라는 의미입니다.  \n",
    "\n",
    "두 개의 토큰을 추가해 주었기 때문에 단어장의 크기도 +2임을 명시해 주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "170a7504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8333\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다. \n",
    "\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4703e78e",
   "metadata": {},
   "source": [
    "## 2. 각 단어를 고유한 정수로 인코딩(Integer encoding) & 패딩(Padding)\n",
    "위에서 tensorflow_datasets의 SubwordTextEncoder를 사용해서 tokenizer를 정의하고 Vocabulary를 만들었다면,   \n",
    "tokenizer.encode()로 각 단어를 정수로 변환할 수 있고 또는 tokenizer.decode()를 통해 정수 시퀀스를 단어 시퀀스로 변환할 수 있습니다.  \n",
    "\n",
    "예를 들어서 22번째 샘플을 tokenizer.encode()의 입력으로 사용해서 변환 결과를 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6960735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [60, 8, 37, 8172, 49]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [7824, 1223, 19, 61, 2, 4, 336, 10, 1595, 14, 1104, 698, 3263, 263, 16, 71, 14, 107, 2133, 900, 3, 59, 4, 23, 355, 204, 60, 8, 37, 885, 2289, 8107, 344, 1001, 5179, 4214, 342, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f43cf56",
   "metadata": {},
   "source": [
    "각 단어에 고유한 정수가 부여된 Vocabulary를 기준으로 단어 시퀀스가 정수 시퀀스로 인코딩된 결과를 확인할 수 있습니다.   \n",
    "위의 결과와 마찬가지로 질문과 답변 셋에 대해서 전부 정수 인코딩 을 수행합니다.     \n",
    "\n",
    "이와 동시에 문장의 최대 길이를 정하고, 해당 길이로 패딩(padding) 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a554f9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60096732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f0e16e",
   "metadata": {},
   "source": [
    "> **패딩 코드 주석**  \n",
    "> tf.keras.preprocessing.sequence.pad_sequences 함수는 시퀀스를 패딩하여 최대 길이(maxlen)에 도달하지 못하는 경우에는 'post' 옵션을 사용하여 패딩을 시행합니다.  \n",
    "> \n",
    "> - tokenized_inputs: 패딩을 적용할 정수 인코딩된 입력 시퀀스의 리스트\n",
    "> - maxlen=MAX_LENGTH: 패딩 후 시퀀스의 최대 길이. MAX_LENGTH로 정의된 값입니다.\n",
    "> - padding='post': 패딩을 시행할 위치. 'post'는 시퀀스의 뒷부분에 패딩을 추가한다는 의미입니다.\n",
    "\n",
    "정수 인코딩 과정을 수행하면서 샘플의 길이가 40을 넘는 경우는 샘플들을 필터링하였으므로 일부 샘플이 제외되었습니다.   \n",
    "단어장의 크기와 샘플의 개수를 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73554384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8333\n",
      "필터링 후의 질문 샘플 개수: 44095\n",
      "필터링 후의 답변 샘플 개수: 44095\n"
     ]
    }
   ],
   "source": [
    "# 단어장의 크기와 샘플의 개수 확인 (최대 길이 40을 넘는 경우를 샘플링한 이후)\n",
    "\n",
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec58d376",
   "metadata": {},
   "source": [
    "## 3. 교사 강요(Teacher Forcing) 사용하기\n",
    "tf.data.Dataset API 는 훈련 프로세스의 속도가 빨라지도록 입력 파이프라인을 구축하는 API입니다.  \n",
    "이를 적극 사용하기 위해서 질문과 답변의 쌍을 tf.data.Dataset의 입력으로 넣어주는 작업을 합니다.  \n",
    "이때, 디코더의 입력과 실제값(레이블)을 정의해 주기 위해서는 교사 강요(Teacher Forcing) 이라는 언어 모델의 훈련 기법을 이해해야만 합니다.   \n",
    "아래의 글을 통해 교사 강요에 대해 알아봅시다. (모두 읽을 필요는 없고, 교사 강요 부분까지만 읽어도 됩니다.)  \n",
    "- [위키독스: RNN 언어 모델](https://wikidocs.net/46496)\n",
    "- [교사 강요](https://jimmy-ai.tistory.com/262) \n",
    "\n",
    "Q. 교사 강요(Teacher Forcing) 를 사용하지 않았을 경우, 훈련 과정에서 훈련 속도가 지나치게 느려지는 경우가 있다고 합니다. 그 이유는 무엇인가요?  \n",
    "A. 교사 강요를 하지 않은 경우, 잘못된 예측이 다음 시점(time step)의 입력으로 들어가면서 연쇄적으로 예측 정확도에 영향을 미친다.  \n",
    "\n",
    "이전 자신의 출력이 현재 자신의 상태를 결정하는 모델을 자기회귀 모델(auto-regressive model, AR) 이라고 합니다.   \n",
    "앞서 교사 강요를 이해하기 위해 읽었던 글에 등장한 RNN 언어 모델은 대표적인 자기 회귀 모델의 예이며, 트랜스포머의 디코더 또한 자기회귀 모델입니다.  \n",
    "\n",
    "트랜스포머 디코더에서도 교사 강요(Teacher Forcing) 를 적용합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e2078f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 만약, answers의 한 샘플이 다음과 같았다고 해봅시다.  \n",
    "\n",
    "# 샘플 : '<START_TOKEN> I AM A STUDENT <END_TOKEN> <PAD> <PAD> <PAD> <PAD>'  \n",
    "\n",
    "# <START_TOKEN>은 문장의 시작을 의미하는 시작 토큰, <END_TOKEN>은 문장의 끝을 의미하는 종료 토큰 <PAD>는 패딩을 위해 사용되는 패딩 토큰입니다.  \n",
    "\n",
    "# 교사 강요를 적용하기 위해서 위 샘플을 디코더의 입력과 레이블로 사용한다고 하였을 때, 각각 어떻게 수정해서 입력과 레이블로 사용해야 할까요?  \n",
    "\n",
    "# A. 입력 : <START_TOKEN> I AM A STUDENT <END_TOKEN> <PAD> <PAD> <PAD> \n",
    "#    레이블 : I AM A STUDENT <END_TOKEN> <PAD> <PAD> <PAD> <PAD>\n",
    "\n",
    "# === 해설 ================================================================================================\n",
    "# 입력 시퀀스는 디코더의 입력으로 사용되며, 레이블 시퀀스는 디코더의 출력과 비교하여 손실을 계산하는 데 사용됩니다.  \n",
    "# - 입력 시퀀스에는 시작 토큰 '<START_TOKEN>'이 포함되어야 합니다. 이는 디코더에게 문장의 시작을 알려주는 역할을 합니다.    \n",
    "# - 레이블 시퀀스에는 시작 토큰이 없으며, 실제 문장인 'I AM A STUDENT'부터 시작합니다.     \n",
    "# 그리고 문장의 끝을 나타내는 종료 토큰 '<END_TOKEN>'이 포함되어야 합니다. 나머지는 패딩 토큰 '<PAD>'으로 채워집니다.  \n",
    "\n",
    "# 이렇게 수정된 입력과 레이블을 사용하여 교사 강요를 적용할 수 있습니다.   \n",
    "# 디코더는 입력 시퀀스를 받아 레이블 시퀀스를 예측하고, 손실을 계산하여 모델을 학습시킬 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a96c50",
   "metadata": {},
   "source": [
    "질문과 답변의 쌍을 tf.data.Dataset API의 입력으로 사용하여 파이프라인을 구성합니다.   \n",
    "이때, 교사 강요를 위해서 answers[:, :-1]를 디코더의 입력값(각 샘플에서 마지막 원소를 제외한 부분),   \n",
    "answers[:, 1:]를 디코더의 레이블(answer의 각 샘플에서 첫번째 원소를 제외한 부분)로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca0ea52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 질문과 답변의 쌍을 tf.data.Dataset API의 입력으로 사용하여 파이프라인을 구성\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()   # 데이터셋을 캐시에 저장하여 훈련 속도를 높입니다.\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)   # 데이터를 GPU로 효율적으로 전달하기 위해 필요한 만큼의 데이터를 미리 준비합니다.\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56776770",
   "metadata": {},
   "source": [
    "# 12. 모델 정의 및 학습하기\n",
    "## 트랜스포머 함수 정의\n",
    "이제 앞서 사용한 인코더 층 함수와 디코더 층 함수를 사용하여 트랜스포머 함수를 정의합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2e22c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 트랜스포머 함수 정의\n",
    "\n",
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")             # 인코더의 입력 텐서\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")     # 디코더의 입력 텐서\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크 : 인코더 입력에 대한 패딩 마스크를 생성 (패딩 토큰을 가리기 위해 사용됨)\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크(가리기) 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크 : 디코더 입력에 대한 패딩 마스크를 생성\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더 : 인코더 레이어를 호출하여 인코더의 출력을 얻는다. (인코더의 입력으로 inputs, enc_padding_mask를 사용한다.)\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더 : 디코더 레이어를 호출하여 디코더의 출력을 얻는다. \n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층 : 디코더의 출력을 완결연결층에 통과시켜 최종 출력을 얻는다. (출력의 크기는 어휘 사전의 크기인 vocab_size와 같음.)\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    # 최족적으로 모델은 'inputs'과 'dec_inputs'을 입력으로 받고, 'outputs'을 출력으로 하는 트랜스포머 모델을 반환한다.\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225f280",
   "metadata": {},
   "source": [
    "**shape 주석**\n",
    "- **enc_padding_mask**에서 output_shape=(1, 1, None): 패딩 마스크의 출력 형태를 지정합니다.\n",
    "    - 첫 번째 차원(1): 배치 크기 (batch size)\n",
    "    - 두 번째 차원(1): 시퀀스 길이 (sequence length)\n",
    "    - 세 번째 차원(None): 패딩 마스크는 가변적인 길이를 가질 수 있으므로, 실제 값은 실행 시간에 결정됩니다.   \n",
    "        \n",
    "따라서, enc_padding_mask의 출력 형태는 (batch_size, 1, 1, sequence_length)이 됩니다.   \n",
    "이 형태는 인코더의 self-attention 메커니즘에서 **패딩 토큰에 대한 가중치를 부여**하는 데 사용됩니다.\n",
    "\n",
    "\n",
    "- **dec_padding_mask**에서 output_shape=(1, None, None): 마스크의 출력 형태를 지정합니다. \n",
    "    - 첫 번째 차원(1): 배치 크기 (batch size)\n",
    "    - 두 번째 차원(None): 시퀀스 길이 (sequence length), 디코더 입력의 각 위치에 대한 미래 토큰을 가리기 위해 가변적인 길이를 가질 수 있습니다.\n",
    "    - 세 번째 차원(None): 시퀀스 길이 (sequence length), 두 번째 차원과 동일한 값으로 마스크의 길이를 나타냅니다.  \n",
    "        \n",
    "따라서, look_ahead_mask의 출력 형태는 (batch_size, None, None)이 됩니다.  \n",
    "이 형태는 디코더의 self-attention 메커니즘에서 미래의 토큰에 대한 정보를 가려서 **현재의 토큰만을 고려하도록** 합니다.\n",
    "\n",
    "\n",
    "- **dec_padding_mask**에서 output_shape=(1, 1, None): 마스크의 출력 형태를 지정합니다. \n",
    "    - 첫 번째 차원(1): 배치 크기 (batch size)\n",
    "    - 두 번째 차원(1): 쿼리(Q), 키(K) 등의 시퀀스 길이 (sequence length)\n",
    "    - 세 번째 차원(None): 시퀀스 길이 (sequence length), 두 번째 차원과 동일한 값으로 마스크의 길이를 나타냅니다.\n",
    "        \n",
    "따라서, dec_padding_mask의 출력 형태는 (batch_size, 1, None)이 됩니다.    \n",
    "이 형태는 디코더의 self-attention 메커니즘에서 입력 문장의 패딩을 가려서 모델이 **패딩 토큰을 무시하도록** 합니다.\n",
    "\n",
    "\n",
    "- **최종적인 outputs의 shape**는 (batch_size, sequence_length, vocab_size)가 됩니다.   \n",
    "이는 각 배치에서 각 시퀀스 타임 스텝마다 어휘 사전에 있는 각 단어에 대한 확률값을 포함하는 형태입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72be0c7a",
   "metadata": {},
   "source": [
    "## 1. 모델 생성\n",
    "**num_layers, d-Model, units는 전부 사용자가 정할 수 있는 하이퍼파라미터 값**입니다.  \n",
    "\n",
    "논문에서 num_layers는 6, d-Model은 512였지만, 빠르고 원활한 훈련을 위해 여기서는 각 하이퍼파라미터를 논문에서보다는 작은 값을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae71c1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3187456     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3714816     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8333)   2141581     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,043,853\n",
      "Trainable params: 9,043,853\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c7c4cd",
   "metadata": {},
   "source": [
    "## 2. 손실 함수(Loss function)\n",
    "레이블인 시퀀스에 패딩이 되어 있으므로, loss를 계산할 때 패딩 마스크를 적용해야 합니다.  \n",
    "여기서 사용되는 손실 함수는 SparseCategoricalCrossentropy로, 희소한 레이블에 대한 다중 분류 손실을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "51177287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 손실함수 구현\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "    # 정답 레이블 y_true를 모델의 출력 y_pred와 크기를 맞추기 위해 재구성.\n",
    "    # -1은 해당 차원의 크기를 자동으로 계산하라는 의미. 각 시퀀스의 길이는 MAX_LENGTH - 1로 설정되어 있음.\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "    # 재구성된 정답 레이블 y_true와 모델의 예측값 y_pred를 사용하여 희소 범주형 크로스엔트로피 손실을 계산\n",
    "    # from_logits=True는 y_pred가 확률 분포가 아니라 로짓(확률에 대한 로그 오즈 비율)을 포함하고 있음을 나타냄\n",
    "    # reduction='none'은 손실의 각 샘플에 대한 값을 유지하도록 지정\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    # '패딩된 부분을 나타내는 값인 0'이 아닌 부분을 1로 표시하는 마스크를 생성. 이 마스크는 손실을 계산할 때 패딩된 부분(0)을 무시하는 데 사용됨.\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    # 손실에 마스크를 적용하여 패딩된 부분의 손실을 0으로 만든다.\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "    # 마지막으로, 손실의 평균을 계산하여 반환합니다. \n",
    "    # 평균을 구하는 이유는 시퀀스의 길이가 다를 수 있기 때문에 각 시퀀스의 손실을 비교 가능한 형태로 만들기 위함입니다.\n",
    "  return tf.reduce_mean(loss)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365b670b",
   "metadata": {},
   "source": [
    "## 3. 커스텀 된 학습률(Learning rate)\n",
    "**딥러닝 모델학습 시 learning rate는 매우 중요한 하이퍼파라미터**입니다.   \n",
    "최근에는 모델학습 초기에 learning rate를 급격히 높였다가, 이후 train step이 진행됨에 따라 서서히 낮추어 가면서 안정적으로 수렴하게 하는 고급 기법을 널리 사용하고 있습니다.   \n",
    "이런 방법을 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)이라고 합니다.   \n",
    "\n",
    "논문에 나온 공식을 참고하여 커스텀 학습률 스케줄러를 통한 아담 옵티마이저를 사용합니다. 논문에 나온 공식은 다음과 같습니다.\n",
    "![공식](/Users/yangh/Desktop/adam_optimizer.png)  \n",
    "\n",
    "lrate = d_model의 -0.5승 * min(step_num의 -0.5승, step_num * warmup_steps의 -1.5승)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "66fa374c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 커스텀 학습률 스케줄러\n",
    "\n",
    "# CustomSchedule 클래스는 tf.keras.optimizers.schedules.LearningRateSchedule 클래스를 상속\n",
    "# 이 클래스에서는 초기 학습률을 1/sqrt(d_model)로 설정하고, warm-up 단계 동안은 선형적으로 증가하도록 설계되어 있다.\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    # d_model은 모델의 내부 차원 수를 나타내며, warmup_steps는 학습률이 선형적으로 증가하는 단계 수\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "    # __call__ 메서드에서는 현재의 학습 단계(step)을 받아서 해당 단계에 대한 학습률을 계산.\n",
    "  def __call__(self, step):\n",
    "    # arg1 및 arg2는 선형적인 증가 부분을 조절하기 위한 인자들\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    # 최종적으로는 arg1과 arg2 중 작은 값을 선택하여 반환합니다.\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662f45c0",
   "metadata": {},
   "source": [
    "그러면 방금 정의한 커스텀 학습률 스케줄링 계획을 시각화해 봅시다.   \n",
    "위에 언급한 수식은 step_num의 -0.5승에 비례하는 부분과 step_num에 비례하는 부분 중 작은 쪽을 택하도록 되어 있습니다.  \n",
    "그래서 학습 초기에는 learning_rate가 step_num에 비례해서 증가하다가 이후로는 감소하는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce226ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 커스텀 학습률 스케줄링 계획 시각화 \n",
    "\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))   # tf.range(200000, dtype=tf.float32)는 학습 단계(step)\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98339b7c",
   "metadata": {},
   "source": [
    "## 4. 모델 컴파일\n",
    "손실 함수와 커스텀 된 학습률(learning rate)을 사용하여 모델을 컴파일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c91a889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# model compile\n",
    "\n",
    "# CustomSchedule 클래스를 사용하여 학습률(learning rate)을 동적으로 조정합니다. \n",
    "# 이 학습률은 Adam 옵티마이저에 적용됩니다. D_MODEL은 모델 내부의 입출력 차원을 나타냅니다.\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "# Adam 옵티마이저를 정의하고, 학습률을 지정합니다. beta_1, beta_2, epsilon 등은 Adam 옵티마이저의 하이퍼파라미터입니다.\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8059383",
   "metadata": {},
   "source": [
    "## 5. 훈련하기\n",
    "이제 학습을 진행해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4bb6a261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "689/689 [==============================] - 81s 106ms/step - loss: 2.1080 - accuracy: 0.0423\n",
      "Epoch 2/10\n",
      "689/689 [==============================] - 73s 106ms/step - loss: 1.4994 - accuracy: 0.0791\n",
      "Epoch 3/10\n",
      "689/689 [==============================] - 73s 106ms/step - loss: 1.3951 - accuracy: 0.0859\n",
      "Epoch 4/10\n",
      "689/689 [==============================] - 73s 106ms/step - loss: 1.3362 - accuracy: 0.0903\n",
      "Epoch 5/10\n",
      "689/689 [==============================] - 73s 106ms/step - loss: 1.2860 - accuracy: 0.0942\n",
      "Epoch 6/10\n",
      "689/689 [==============================] - 66s 96ms/step - loss: 1.2390 - accuracy: 0.0980\n",
      "Epoch 7/10\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 1.1844 - accuracy: 0.1021\n",
      "Epoch 8/10\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 1.1223 - accuracy: 0.1074\n",
      "Epoch 9/10\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 1.0647 - accuracy: 0.1130\n",
      "Epoch 10/10\n",
      "689/689 [==============================] - 37s 54ms/step - loss: 1.0113 - accuracy: 0.1190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca5443e250>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model fit\n",
    "\n",
    "EPOCHS = 10\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb85939",
   "metadata": {},
   "source": [
    "# 13. 챗봇 테스트하기\n",
    "예측(inference) 단계는 기본적으로 다음과 같은 과정을 거칩니다.  \n",
    "\n",
    "1. 새로운 입력 문장에 대해서는 훈련 때와 동일한 전처리를 거친다.\n",
    "2. 입력 문장을 토크나이징하고, START_TOKEN과 END_TOKEN을 추가한다.\n",
    "3. 패딩 마스킹과 룩 어헤드 마스킹을 계산한다.\n",
    "4. 디코더는 입력 시퀀스로부터 다음 단어를 예측한다.\n",
    "5. 디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
    "6. END_TOKEN이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춘다.  \n",
    "\n",
    "위의 과정을 모두 담은 decoder_inference() 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c8daa8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 예측 단계 : decoder_inference() 함수 구현\n",
    "\n",
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]   # 마지막 시점의 정보만 선택\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    # 주어진 텐서 predictions에서 마지막 차원(가장 안쪽의 차원 / axis=1 / 어휘 크기)을 따라 최댓값을 가지는 요소의 인덱스를 반환\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료 (END_TOKEN[0]은 종료 토큰의 정수 인덱스)\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    # output_sequence 텐서에서 크기가 1인 차원을 제거 (디코더의 인퍼런스 프로세스 중에 생성된 시퀀스를 반환할 때 사용됨)\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "\n",
    "# 기본적으로 디코더의 인퍼런스는 현재까지의 예측된 시퀀스를 계속해서 누적하면서 진행됩니다. \n",
    "# 그러나 모델의 출력이 배치 차원을 가지고 있기 때문에, 이를 제거하고 최종 시퀀스를 반환하기 위해 tf.squeeze를 사용합니다. \n",
    "# 반환된 시퀀스는 실제 단어의 인덱스를 포함하며, 이는 모델이 생성한 문장입니다.\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d44a2",
   "metadata": {},
   "source": [
    "**predictions 텐서 주석**  \n",
    "- [:, -1:, :]: 텐서의 첫 번째 축(배치 축)은 모든 예시(batch)에 대한 정보를 나타냅니다. \n",
    "    - [:, -1:, :]는 마지막 시점의 정보만 선택하고자 하는 인덱싱을 나타냅니다.  \n",
    "    \n",
    "\n",
    "- 예를 들어, predictions가 (배치 크기, 시퀀스 길이, 어휘 크기)의 모양을 가진 3D 텐서라면, predictions[:, -1:, :]는 모든 예시에 대해 시퀀스의 마지막 단어에 해당하는 부분을 선택합니다.   \n",
    "결과로 나오는 텐서는 (배치 크기, 1, 어휘 크기) 모양을 가지게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a125ae",
   "metadata": {},
   "source": [
    "임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는 sentence_generation() 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b1d12b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 챗봇의 대답을 얻는 함수 구현 : decoder_inference() 함수를 호출하여\n",
    "\n",
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2391c7",
   "metadata": {},
   "source": [
    "### 임의의 문장으로부터 챗봇의 대답을 얻어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af1d07cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : Where have you been?\n",
      "출력 : i m not gonna put it in a few days .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i m not gonna put it in a few days .'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('Where have you been?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c7fcb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : It's a trap\n",
      "출력 : i m sorry , but i can t understand it . i can t even help you .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i m sorry , but i can t understand it . i can t even help you .'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"It's a trap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcffa920",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce88dd2f",
   "metadata": {},
   "source": [
    "## 회고\n",
    "- 전체 단계가 매우 많고, 적용되는 개념들도 이해하기 어렵다.\n",
    "    - 전체 흐름과 개념들을 이해하기 쉬운 다른 자료들을 찾아봐야겠다.\n",
    "- 사용되는 함수가 너무 많아서 그 함수가 어떤 기능이었는지, 어디에서 사용되는지 정리가 안된다.\n",
    "    - 각 단계 별 함수와 기능을 정리해봐야겠다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
