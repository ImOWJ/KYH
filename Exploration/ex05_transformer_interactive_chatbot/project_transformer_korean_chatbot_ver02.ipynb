{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "170f7ecb",
   "metadata": {},
   "source": [
    "# 프로젝트: 한국어 데이터로 챗봇 만들기\n",
    "## 개요\n",
    "영어로 만들었던 챗봇을 한국어 데이터로 바꿔서 훈련시켜봅니다.   \n",
    "\n",
    "## 목차\n",
    "- Step 1. 데이터 수집하기\n",
    "- Step 2. 데이터 전처리하기\n",
    "- Step 3. SubwordTextEncoder 사용하기\n",
    "- Step 4. 모델 구성하기\n",
    "- Step 5. 모델 평가하기\n",
    "\n",
    "## 회고\n",
    "\n",
    "## Reference\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d9b56d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "# 주요 라이브러리 버전 확인\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf71c6",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56c6640",
   "metadata": {},
   "source": [
    "한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용합니다.  \n",
    "이 데이터는 아래의 링크에서 다운로드할 수 있습니다.  \n",
    "- [songys/Chatbot_data](https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv)  \n",
    "\n",
    "cloud shell에서 디렉토리를 생성하고 데이터 디렉토리와 연결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915d8dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ mkdir -p ~/aiffel/transformer_chatbot/data/\n",
    "# $ ln -s ~/data/* ~/aiffel/transformer_chatbot/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316f360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 패키지 임포트\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e75a42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 \n",
    "\n",
    "data = pd.read_csv(os.getenv('HOME') + '/aiffel/transformer_chatbot/data/ChatbotData .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7910772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 샘플 확인하기 \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9b0410d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 11823\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터 수\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ca9ae69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "\n",
    "MAX_SAMPLES = len(data)\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece20482",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 전처리하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f020c4",
   "metadata": {},
   "source": [
    "한국어 데이터를 영어 데이터와 비교해보았을 때,  \n",
    "- 공통점 : 구두점을 제거하여 단어를 토크나이징, 질문과 답변의 쌍을 전처리, 병렬 데이터 전처리\n",
    "- 차이점 : 대소문자 변환이 필요 없음, 띄어쓰기가 문맥과 의미를 구분하는 데에 큰 영향을 준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f56a6b",
   "metadata": {},
   "source": [
    "---\n",
    "띄어쓰기와 맞춤법 검사 전처리를 하고싶었으나 오류가 해결되지 않아 skip하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d8d1488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Collecting git+https://github.com/haven-jeon/PyKoSpacing.git\n",
      "  Cloning https://github.com/haven-jeon/PyKoSpacing.git to /tmp/pip-req-build-tc6aog2y\n",
      "  Running command git clone --filter=blob:none -q https://github.com/haven-jeon/PyKoSpacing.git /tmp/pip-req-build-tc6aog2y\n",
      "  Resolved https://github.com/haven-jeon/PyKoSpacing.git to commit 04aeebcbe26b109486a642e57dc58665c4818cf3\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow==2.11.1\n",
      "  Using cached tensorflow-2.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
      "Collecting h5py==3.10.0\n",
      "  Using cached h5py-3.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "Collecting argparse>=1.4.0\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from h5py==3.10.0->pykospacing==0.5) (1.19.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.11.1->pykospacing==0.5) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.11.1->pykospacing==0.5) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.11.1->pykospacing==0.5) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.11.1->pykospacing==0.5) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.11.1->pykospacing==0.5) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.11.1->pykospacing==0.5) (0.2.0)\n",
      "Collecting numpy>=1.17.3\n",
      "  Downloading numpy-1.26.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "     |████████████████████████████████| 18.2 MB 8.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.11.1->pykospacing==0.5) (3.19.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.11.1->pykospacing==0.5) (59.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.11.1->pykospacing==0.5) (0.35.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.11.1->pykospacing==0.5) (1.6.3)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.11.1->pykospacing==0.5) (0.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.11.1->pykospacing==0.5) (21.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.11.1->pykospacing==0.5) (16.0.6)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.11.1->pykospacing==0.5) (2.11.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.11.1->pykospacing==0.5) (1.42.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.11.1->pykospacing==0.5) (2.11.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow==2.11.1->pykospacing==0.5) (0.37.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (2.3.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (2.26.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (0.6.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->tensorflow==2.11.1->pykospacing==0.5) (3.0.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (4.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (2.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.1->pykospacing==0.5) (3.1.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Installing collected packages: numpy, absl-py, tensorflow-estimator, h5py, flatbuffers, tensorflow, argparse\n",
      "  Attempting uninstall: numpy\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: absl-py\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "    Found existing installation: absl-py 0.15.0\n",
      "    Uninstalling absl-py-0.15.0:\n",
      "      Successfully uninstalled absl-py-0.15.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "    Found existing installation: tensorflow-estimator 2.15.0\n",
      "    Uninstalling tensorflow-estimator-2.15.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
      "  Attempting uninstall: h5py\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "  Attempting uninstall: flatbuffers\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "    Found existing installation: flatbuffers 1.12\n",
      "    Uninstalling flatbuffers-1.12:\n",
      "      Successfully uninstalled flatbuffers-1.12\n",
      "  Attempting uninstall: tensorflow\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "    Found existing installation: tensorflow 2.6.0\n",
      "    Uninstalling tensorflow-2.6.0:\n",
      "      Successfully uninstalled tensorflow-2.6.0\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 띄어쓰기 라이브러리 설치\n",
    "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9718755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "Collecting git+https://github.com/haven-jeon/PyKoSpacing.git\n",
      "  Cloning https://github.com/haven-jeon/PyKoSpacing.git to /tmp/pip-req-build-cbz4c07x\n",
      "  Running command git clone --filter=blob:none -q https://github.com/haven-jeon/PyKoSpacing.git /tmp/pip-req-build-cbz4c07x\n",
      "  Resolved https://github.com/haven-jeon/PyKoSpacing.git to commit 04aeebcbe26b109486a642e57dc58665c4818cf3\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: argument in /opt/conda/lib/python3.9/site-packages (1.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.9/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 띄어쓰기 라이브러리 설치\n",
    "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git --no-deps argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "884d36fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.util.dispatch' has no attribute 'add_fallback_dispatch_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_161/1788311097.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 띄어쓰기가 잘 되는지 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpykospacing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'V리그 여자부 흥국생명이 김연경과 옐레나의 쌍포를 앞세워 가장 먼저 10승 고지를 밟았다. 흥국생명은 25일 홈경기에서 도로공사를 상대로 세트 스코어 3대0(27-25 25-20 25-19) 완승을 거뒀다.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pykospacing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpykospacing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkospacing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pykospacing/kospacing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpykospacing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_maker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mencoding_and_padding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/api/_v2/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \"\"\"\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayout_map\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_coordinator_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_flow_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# isort: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Internal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_source_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Deprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/layer_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/initializers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# isort: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/dtensor/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Conditional import the dtensor API, since it is currently broken in OSS.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_DTENSOR_API_ENABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdtensor_api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Leave it with a placeholder, so that the import line from other python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/_api/v2/compat/v2/experimental/dtensor/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitialize_accelerator_system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitialize_accelerator_system\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minitialize_multi_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitialize_accelerator_system\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minitialize_tpu_system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/dtensor/python/accelerator_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcluster_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_server_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtpu_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/dtensor/python/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtensor_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_dtensor_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayout\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlayout_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/dtensor/python/dtensor_device.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_dtensor_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayout\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlayout_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_dtensor_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/dtensor/python/gen_dtensor_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_fallback_dispatch_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_type_based_api_dispatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'configure_and_initialize_global_tpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.util.dispatch' has no attribute 'add_fallback_dispatch_list'"
     ]
    }
   ],
   "source": [
    "# 띄어쓰기가 잘 되는지 확인\n",
    "\n",
    "from pykospacing import Spacing\n",
    "\n",
    "sentence = 'V리그 여자부 흥국생명이 김연경과 옐레나의 쌍포를 앞세워 가장 먼저 10승 고지를 밟았다. 흥국생명은 25일 홈경기에서 도로공사를 상대로 세트 스코어 3대0(27-25 25-20 25-19) 완승을 거뒀다.'\n",
    "sentence = sentence.replace(\" \", '') # 띄어쓰기가 없는 문장 임의로 만들기\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b409f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__ = \"2.6.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow 2.6.0에서 호환성을 유지하기 위해 tensorflow.compat.v1을 사용\n",
    "import tensorflow.compat.v1 as tf_compat\n",
    "tf_compat.disable_v2_behavior()\n",
    "\n",
    "# PyKoSpacing을 불러올 때 에러가 발생하지 않도록 모델 로딩 시 예외 처리 추가\n",
    "try:\n",
    "    from pykospacing import Spacing\n",
    "except Exception as e:\n",
    "    print(\"Error loading PyKoSpacing:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533db500",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'V리그 여자부 흥국생명이 김연경과 옐레나의 쌍포를 앞세워 가장 먼저 10승 고지를 밟았다. 흥국생명은 25일 홈경기에서 도로공사를 상대로 세트 스코어 3대0(27-25 25-20 25-19) 완승을 거뒀다.'\n",
    "sentence = sentence.replace(\" \", '') # 띄어쓰기가 없는 문장 임의로 만들기\n",
    "\n",
    "# PyKoSpacing 모델이 로드되었는지 확인 후 사용\n",
    "if 'Spacing' in locals():\n",
    "    spacing = Spacing()\n",
    "    spaced_sentence = spacing(sentence)\n",
    "    print(spaced_sentence)\n",
    "else:\n",
    "    print(\"PyKoSpacing 모델이 로드되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e64ef",
   "metadata": {},
   "source": [
    "텐서플로우 버전 호환의 문제로 보이나 현재 버전을 유지하고 싶어서 다른 띄어쓰기&맞춤법 검사 패키지인 Py-Hanspell을 써보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2580ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install py-hanspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c29fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Py-Hanspell 패키지 불러오기\n",
    "\n",
    "from hanspell import spell_checker\n",
    "\n",
    "sentence = 'V리그 여자부 흥국생명이 김연경과 옐레나의 쌍포를 앞세워 가장 먼저 10승 고지를 밟았다. 흥국생명은 25일 홈경기에서 도로공사를 상대로 세트 스코어 3대0(27-25 25-20 25-19) 완승을 거뒀다.'\n",
    "spelled_sent = spell_checker.check(sentence)\n",
    "\n",
    "sentence = spelled_sent.checked\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7209dd",
   "metadata": {},
   "source": [
    "---\n",
    "띄어쓰기 전처리가 쉽지 않습니다. 일단은 구두점 전처리를 진행해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72bde810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 전처리 함수\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  # (한글, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "  sentence = re.sub(r\"[^ㄱ-ㅎ가-힣?.!,]+\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "    \n",
    "  return sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5346e2e",
   "metadata": {},
   "source": [
    "## 질문과 답변의 쌍을 전처리\n",
    "csv 파일에 이미 질문과 답변으로 구분되어 있으므로 변수에 담아 확인 작업만 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "569b4f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍 확인\n",
    "questions = [preprocess_sentence(sentence) for sentence in data['Q']]\n",
    "answers = [preprocess_sentence(sentence) for sentence in data['A']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a0d691c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 샘플 수 확인\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97adaf5",
   "metadata": {},
   "source": [
    "질문과 답변의 샘플 수가 일치하는 것을 확인했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "113a1779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 .\n"
     ]
    }
   ],
   "source": [
    "# 질문과 답변의 쌍 테스트 \n",
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed68ab0",
   "metadata": {},
   "source": [
    "# Step 3. SubwordTextEncoder 사용하기\n",
    "\n",
    "## 병렬 데이터 전처리 하기\n",
    "질문과 답변의 셋을 각각 questions과 answers에 저장하였으므로, 본격적으로 전처리를 진행해보겠습니다.  \n",
    "이번 스텝에서 진행할 전체적인 과정을 요약하면 다음과 같습니다.  \n",
    "\n",
    "1. TensorFlow Datasets SubwordTextEncoder 를 토크나이저로 사용한다.  \n",
    "단어보다 더 작은 단위인 Subword를 기준으로 토크나이징하고, 각 토큰을 고유한 정수로 인코딩 한다.\n",
    "2. 각 문장을 토큰화하고 각 문장의 시작과 끝을 나타내는 START_TOKEN 및 END_TOKEN을 추가한다.\n",
    "3. 최대 길이 MAX_LENGTH 인 40을 넘는 문장들은 필터링한다.\n",
    "4. MAX_LENGTH보다 길이가 짧은 문장들은 40에 맞도록 패딩 한다.  \n",
    "\n",
    "## 1. 단어장(Vocabulary) 만들기\n",
    "우선 각 단어에 고유한 정수 인덱스를 부여하기 위해서 단어장(Vocabulary)을 만들어보겠습니다.  \n",
    "단어장을 만들 때는 질문과 답변 데이터셋을 모두 사용하여 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2409c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료\n",
      "슝=3 \n"
     ]
    }
   ],
   "source": [
    "# TensorFlow Datasets SubwordTextEncoder를 토크나이저로 import\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "print(\"완료\")\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "print(\"슝=3 \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aee11e4",
   "metadata": {},
   "source": [
    "## 시작 토큰, 종료 토큰에 고유한 정수 부여\n",
    "이때 디코더의 문장 생성 과정에서 사용할 '시작 토큰'과 '종료 토큰'에 대해서도 임의로 단어장에 추가하여서 정수를 부여해 줍니다.  \n",
    "이미 생성된 단어장의 번호와 겹치지 않도록 각각 단어장의 크기와 그보다 1이 큰 수를 번호로 부여하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9169d4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04e873a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8129]\n",
      "END_TOKEN의 번호 : [8130]\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 부여된 정수 출력해보기 \n",
    "\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ebe51",
   "metadata": {},
   "source": [
    "각각 8,129과 8,130라는 점에서 현재 단어장의 크기가 8,129(0번부터 8,128번)이라는 의미입니다.  \n",
    "2개의 토큰을 추가해주었기 때문에 단어장의 크기도 +2임을 명시해주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39f8d497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8131\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다. \n",
    "\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c8e76c",
   "metadata": {},
   "source": [
    "## 2. 각 단어를 고유한 정수로 인코딩(Integer encoding) & 패딩(Padding)\n",
    "위에서 tensorflow_datasets의 SubwordTextEncoder를 사용해서 tokenizer를 정의하고 Vocabulary를 만들었으므로,\n",
    "tokenizer.encode()로 각 단어를 정수로 변환할 수 있고 또는 tokenizer.decode()를 통해 정수 시퀀스를 단어 시퀀스로 변환할 수 있습니다.\n",
    "\n",
    "예를 들어서 22번째 샘플을 tokenizer.encode()의 입력으로 사용해서 변환 결과를 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c7f0ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5744, 612, 2483, 4149]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2352, 7483, 7, 6248, 97, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d1c07",
   "metadata": {},
   "source": [
    "각 단어에 고유한 정수가 부여된 Vocabulary를 기준으로 단어 시퀀스가 정수 시퀀스로 인코딩된 결과를 확인할 수 있습니다.  \n",
    "위의 결과와 마찬가지로 질문과 답변 셋에 대해서 전부 정수 인코딩 을 수행합니다.  \n",
    "문장의 최대 길이를 정하고, 해당 길이로 패딩(padding)합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "524deb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa18eea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec1d1eb",
   "metadata": {},
   "source": [
    "> **패딩 코드 주석**   \n",
    "> tf.keras.preprocessing.sequence.pad_sequences 함수는 시퀀스를 패딩하여 최대 길이(maxlen)에 도달하지 못하는 경우에는 'post' 옵션을 사용하여 패딩을 시행합니다.\n",
    ">\n",
    "> - tokenized_inputs: 패딩을 적용할 정수 인코딩된 입력 시퀀스의 리스트\n",
    "> - maxlen=MAX_LENGTH: 패딩 후 시퀀스의 최대 길이. MAX_LENGTH로 정의된 값입니다.\n",
    "> - padding='post': 패딩을 시행할 위치. 'post'는 시퀀스의 뒷부분에 패딩을 추가한다는 의미입니다.  \n",
    "    \n",
    "정수 인코딩 과정을 수행하면서 샘플의 길이가 40을 넘는 경우는 샘플들을 필터링하였으므로 일부 샘플이 제외되었습니다.\n",
    "단어장의 크기와 샘플의 개수를 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6774a5e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8131\n",
      "필터링 후의 질문 샘플 개수: 11823\n",
      "필터링 후의 답변 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "# 단어장의 크기와 샘플의 개수 확인 (최대 길이 40을 넘는 경우를 샘플링한 이후)\n",
    "\n",
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8885fa",
   "metadata": {},
   "source": [
    "> 위의 코드를 실행했을 때 오류가 발생하였다. 텐서플로우의 버전을 바꿔보았으나 해결이 되지 않았고, 커널을 죽였다가 다시 켜보니 정상적으로 돌아갔다.  \n",
    "이렇게 꼬였을 때는 커널을 죽였다가 다시 실행해보는 것도 방법임을 배웠다!  \n",
    ">\n",
    ">[오류 코드]\n",
    "AttributeError: module 'tensorflow.python.util.dispatch' has no attribute 'add_fallback_dispatch_list'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73f7663",
   "metadata": {},
   "source": [
    "## 3. 교사 강요(Teacher Forcing) 사용하기\n",
    "tf.data.Dataset API 는 훈련 프로세스의 속도가 빨라지도록 입력 파이프라인을 구축하는 API입니다.  \n",
    "이를 적극 사용하기 위해서 질문과 답변의 쌍을 tf.data.Dataset의 입력으로 넣어주는 작업을 합니다.    \n",
    "\n",
    "질문과 답변의 쌍을 tf.data.Dataset API의 입력으로 사용하여 파이프라인을 구성합니다.  \n",
    "이때, 교사 강요를 위해서 answers[:, :-1]를 디코더의 입력값(각 샘플에서 마지막 원소를 제외한 부분),  \n",
    "answers[:, 1:]를 디코더의 레이블(answer의 각 샘플에서 첫번째 원소를 제외한 부분)로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "809085cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 질문과 답변의 쌍을 tf.data.Dataset API의 입력으로 사용하여 파이프라인을 구성\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()   # 데이터셋을 캐시에 저장하여 훈련 속도를 높입니다.\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)   # 데이터를 GPU로 효율적으로 전달하기 위해 필요한 만큼의 데이터를 미리 준비합니다.\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01cbfd1",
   "metadata": {},
   "source": [
    "# Step 4. 모델 구성하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fcb256",
   "metadata": {},
   "source": [
    "## 포지셔널 인코딩\n",
    "트랜스포머는 입력을 받을 때, 문장에 있는 단어들을 1개씩 순차적으로 받는 것이 아니라, 문장에 있는 모든 단어를 한꺼번에 입력으로 받습니다.  \n",
    "따라서 위치와 맥락 정보를 제대로 적용하기 어려우므로 임베딩 행렬과 포지셔널 행렬이라는 두 행렬을 더함으로써 각 단어 벡터에 위치 정보를 더해줍니다.  \n",
    "\n",
    "### 포지셔널 행렬 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f0aa4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    # PositionalEncoding 메서드 : 포지셔널 인코딩을 위한 각도 배열을 생성\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    # positional_encoding 메서드를 호출하여 pos_encoding 변수에 저장\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    # get_anfles 메서드 : 각도 배열을 생성하기 위해 사용. 주어진 위치(position), 인덱스(i), 및 임베딩 차원(d_model)에 대한 각도를 계산.\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "    # positional_encoding : 각도 배열을 생성하고, 짝수 인덱스에는 사인 함수를, 홀수 인덱스에는 코사인 함수를 적용한 후, sin과 cosine이 교차되도록 재배열 \n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    # 입력에 포지셔널 인코딩 값을 더하여 반환. 포지셔널 인코딩의 길이를 입력의 길이에 맞게 자릅니다.\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7e6b72",
   "metadata": {},
   "source": [
    "## 어텐션\n",
    "어텐션 함수는 주어진 '쿼리(Query)'에 대해서 모든 '키(Key)'와의 유사도를 각각 구합니다.  \n",
    "구해낸 이 유사도를 키(Key)와 맵핑되어있는 각각의 '값(Value)'에 반영해 줍니다.  \n",
    "유사도가 반영된 '값(Value)'을 모두 더해서 뭉쳐주면 이를 최종 결과인 어텐션 값(Attention Value) 라고 합니다.\n",
    "\n",
    "### 스케일드 닷 프로덕트 어텐션 구현하기\n",
    "내적(dot product)을 통해 단어 벡터 간 유사도를 구한 후에, 특정 값을 분모로 나눠주는 방식으로 Q와 K의 유사도를 구한 스케일드 닷 프로덕트 어텐션 함수를 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7424eb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # matmul_qk: Query(Q)와 Key(K) 간의 닷 프로덕트를 계산. 이는 어텐션 가중치를 구하기 위한 중간 단계. 어텐션 가중치는 Q와 K의 닷 프로덕트.\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    # logits : 닷 프로덕트를 행렬의 깊이(depth)로 나누어 스케일링을 수행\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가 : mask가 주어졌다면, 어텐션 가중치에 패딩에 대한 마스크를 적용\n",
    "    # 패딩은 어텐션 계산 시 무시되어야 하므로, 해당 위치의 어텐션 가중치를 크게 음의 무한대로 만듭니다.\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용 : Softmax 함수를 사용하여 어텐션 가중치를 계산. 이는 어텐션 가중치를 확률 분포로 만듭니다.\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V(Value)의 닷 프로덕트 -> 이를 통해 쿼리에 대한 어텐션 값을 계산\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c55cbf",
   "metadata": {},
   "source": [
    "> 참조 : np.matmul()은 매트릭스, 행렬 곱을 수행하는 메소드  \n",
    "\n",
    "\n",
    "### 멀티헤드 어텐션 구현하기\n",
    "내부적으로는 스케일드 닷 프로덕트 어텐션 함수를 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c856fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 멀티 헤드 어텐션 구현하기\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리(헤드)를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dbbf50",
   "metadata": {},
   "source": [
    "**스케일드 닷 프로덕트 어텐션 함수 주석**\n",
    "\n",
    "\n",
    "이 부분은 Multi-Head Attention에서 각 헤드에서 계산된 어텐션 가중치를 조작하는 부분입니다.  \n",
    "Multi-Head Attention은 여러 헤드에서 각기 다른 어텐션 가중치를 계산하고, 이를 나중에 결합(concatenate)하여 최종 결과를 얻습니다.  \n",
    "\n",
    "여기서 scaled_attention은 scaled_dot_product_attention 함수를 통해 얻어진 어텐션 가중치 행렬입니다.  \n",
    "\n",
    "1. tf.transpose(scaled_attention, perm=[0, 2, 1, 3]):\n",
    "- 어텐션 가중치 행렬의 차원을 조정합니다.\n",
    "- scaled_attention의 형태는 (batch_size, num_heads, sequence_length, depth)이며, 여기서 sequence_length는 입력 시퀀스의 길이, depth는 각 헤드의 차원입니다.\n",
    "- perm=[0, 2, 1, 3]는 차원의 순서를 조정하는데, 두 번째와 세 번째 차원을 서로 바꾸어주어 헤드별로 어텐션 가중치를 정렬합니다.\n",
    "- 결과적으로 어텐션 가중치 행렬의 형태는 (batch_size, sequence_length, num_heads, depth)이 됩니다.\n",
    "\n",
    "2. tf.reshape(scaled_attention, (batch_size, -1, self.d_model)):\n",
    "- tf.reshape를 사용하여 행렬의 형태를 조정합니다.\n",
    "- -1은 해당 차원의 크기를 자동으로 계산하라는 의미입니다. 여기서는 num_heads * depth에 해당하는 값이 됩니다.\n",
    "- 결과적으로 최종 어텐션 가중치의 형태는 (batch_size, sequence_length, d_model)이 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db57267",
   "metadata": {},
   "source": [
    "## 마스킹\n",
    "### 패딩 마스킹(Padding Masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22a30956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 패딩 마스킹 함수 구현\n",
    "\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(\"슝=3\")\n",
    "\n",
    "# tf.math.equal(x, 0) : 입력 x에서 값이 0인 위치를 찾아 True로 표시한 불리언 텐서를 생성합니다. 이는 패딩 토큰에 해당하는 위치를 나타냅니다.\n",
    "# tf.cast(..., tf.float32) : \n",
    "# 불리언 텐서를 0 또는 1의 값을 가지는 실수형 텐서로 변환. 따라서 패딩 토큰의 위치는 1의 값을 가지고, 나머지 위치는 0의 값을 가지게 됩니다.\n",
    "# mask[:, tf.newaxis, tf.newaxis, :]:\n",
    "# 마스크 텐서의 차원을 확장합니다. tf.newaxis를 사용하여 새로운 축을 추가하고, 이를 통해 적절한 차원을 맞춥니다.\n",
    "# 최종적으로 반환되는 패딩 마스크의 형태는 (batch_size, 1, 1, sequence_length)가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dc8c3c",
   "metadata": {},
   "source": [
    "이 함수에 정수 시퀀스를 입력으로 하면, 이 함수는 숫자가 0인 부분을 체크한 벡터를 리턴합니다.  \n",
    "(이 함수를 호출하면 입력 시퀀스에서 패딩 토큰에 해당하는 위치를 가리키는 패딩 마스크가 생성되어 반환됩니다.   \n",
    "이 마스크는 어텐션 연산에서 패딩 토큰의 영향을 배제하는 데 사용됩니다.)  \n",
    "\n",
    "두 개의 정수 시퀀스를 입력으로 해보고, 각각 어떤 결과가 나오는지 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ae23d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 테스트 - 2개의 정수 시퀀스 입력해보기\n",
    "\n",
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71fa4d9",
   "metadata": {},
   "source": [
    "두 정수 시퀀스에 대해서 각각 결과가 출력되는데, 오직 숫자가 0인 위치에서만 숫자 1이 나오고 숫자 0이 아닌 위치에서는 숫자 0인 벡터를 출력합니다.  \n",
    "어텐션 연산 시에 패딩 마스킹을 참고하면 불필요하게 숫자 0을 참고하지 않게 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5441cdc",
   "metadata": {},
   "source": [
    "### Look-ahead masking : 다음 단어 가리기\n",
    "트랜스포머의 경우에는 문장 행렬을 만들어 한 번에 행렬 형태로 입력으로 들어간다는 특징이 있습니다.  \n",
    "그리고 이 특징 때문에 추가적인 마스킹(Masking) 을 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db29419f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# look-ahead masking 함수 구현 (빨강색 부분 = 다음 단어 가리기)\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "    # 입력 x의 시퀀스 길이를 구합니다. 즉, 시퀀스의 두 번째 차원의 크기를 가져와서 seq_len 변수에 저장합니다.\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(\"슝=3\")\n",
    "\n",
    "\n",
    "# look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0):\n",
    "# tf.ones((seq_len, seq_len))를 사용하여 모든 원소가 1인 행렬을 만듭니다.\n",
    "# tf.linalg.band_part(..., -1, 0)를 사용하여 행렬의 아래 삼각행렬을 0으로 만들고, 위 삼각행렬은 1로 남깁니다.\n",
    "# 1 - ...를 통해 원래의 위 삼각행렬이 0이 되고, 아래 삼각행렬이 1이 되도록 합니다. 이것이 룩 어헤드 마스크입니다.\n",
    "\n",
    "# padding_mask = create_padding_mask(x): 앞서 정의한 create_padding_mask 함수를 사용하여 패딩 마스크를 생성합니다.\n",
    "\n",
    "# tf.maximum(look_ahead_mask, padding_mask):\n",
    "# 룩 어헤드 마스크와 패딩 마스크 중에서 더 큰 값을 선택합니다. \n",
    "# 이는 룩 어헤드 마스크와 패딩 마스크 중에서 더 큰 영향을 주는 위치를 선택하는 것으로, 어텐션 연산에서 사용될 마스크를 결정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fad5f5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 직접 입력을 넣어 테스트 해보기\n",
    "\n",
    "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c02387",
   "metadata": {},
   "source": [
    "## 인코더\n",
    "### 인코더 층 만들기\n",
    "하나의 인코더 층은 크게 총 2개의 서브 층(sublayer)으로 나누어집니다.\n",
    "\n",
    "- 인코더 층 = 셀프 어텐션 + 피드 포워드 신경망\n",
    "- 셀프 어텐션은 멀티 헤드 어텐션으로 병렬적으로 이루어집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64783576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 층 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")   \n",
    "    # shape=(배치 사이즈, 헤드의 수, 시퀀스 길이)\n",
    "    # 시퀀스의 길이 = None : 입력 시퀀스의 길이에 따라 동적으로 조정될 수 있다는 의미\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행 (어텐션의 결과는 드롭아웃과 레이어 정규화를 거친다.)\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c24abf",
   "metadata": {},
   "source": [
    "### 인코더 층을 쌓아 인코더 만들기\n",
    "인코더 층을 임베딩 층(Embedding layer)과 포지셔널 인코딩(Positional Encoding)을 연결하고,  \n",
    "사용자가 원하는 만큼 인코더 층을 쌓음으로써 트랜스포머의 인코더가 완성됩니다.  \n",
    "\n",
    "인코더와 디코더 내부에서는 각 서브 층 이후에 훈련을 돕는 Layer Normalization이라는 테크닉이 사용되었습니다.  \n",
    "위 그림에서는 Normalize라고 표시된 부분에 해당됩니다.  \n",
    "\n",
    "트랜스포머는 하이퍼파라미터인 num_layers 개수의 인코더 층을 쌓습니다.  \n",
    "논문에서는 총 6개의 인코더 층을 사용하였지만, 실습에서는 학습 시간을 고려하여 그보다 적은 개수를 사용할 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed3607cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 구현\n",
    "\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")   # inputs: 모델의 입력으로서 단어 인덱스들을 나타냅니다.\n",
    "\n",
    "  # 패딩 마스크 사용 (encoder_layer 함수에서 사용됨)\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)   # 단어 인덱스들을 임베딩하여 단어 벡터를 생성\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))   # 임베딩 차원에 루트를 씌워줌으로써 스케일 조정을 수행합니다.\n",
    "\n",
    "  # 포지셔널 인코딩 : 임베딩 된 단어 벡터에 포지셔널 인코딩 처리 (입력 시퀀스의 각 단어 위치에 대한 상대적인 정보를 주입하는 역할)\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)  # 드롭아웃을 적용하여 모델의 일반화 능력을 향상시킴\n",
    "\n",
    "  # 여러 개의 인코더 레이어 쌓기 : num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2750bb32",
   "metadata": {},
   "source": [
    "**def encoder 인자 뜯어보기**  \n",
    "\n",
    "- vocab_size : 모델이 다루는 어휘 집합(Vocabulary size)의 크기를 나타냅니다.\n",
    "\n",
    "    - 어휘 집합은 모델이 이해하고 다루는 단어나 토큰들의 총 개수를 말합니다.\n",
    "    - 트랜스포머 모델은 입력으로 어휘 집합의 각 단어를 나타내는 정수 인덱스를 받습니다. vocab_size는 이러한 정수 인덱스의 범위를 나타냅니다.\n",
    "    - 예를 들어, 만약 어휘 집합에 10,000개의 고유한 단어가 있다면 vocab_size는 10,000이 됩니다.\n",
    "    - 일반적으로 어휘 집합의 크기는 자주 등장하는 단어를 포함할 수 있도록 설정됩니다.\n",
    "    - 이 값은 모델의 입력 임베딩 레이어의 크기 및 학습 가능한 파라미터의 수에 영향을 미치게 됩니다.\n",
    "    \n",
    "- num_layers : 트랜스포머 모델의 인코더나 디코더에서 사용되는 레이어의 개수\n",
    "\n",
    "    - 일반적으로 모델의 용량(capacity)을 늘리려면 레이어의 수를 늘리고, 그에 따라 학습할 수 있는 특징의 수가 증가합니다.\n",
    "    - num_layers=6으로 설정하면 인코더나 디코더에서 각각 6개의 레이어를 쌓게 됩니다.\n",
    "    - 이 값은 주로 모델의 복잡성과 데이터의 특성에 따라 조절되며, 실험과 검증을 통해 최적의 값을 찾게 됩니다.\n",
    "   \n",
    "- units : 트랜스포머의 인코더 레이어나 디코더 레이어에서 사용되는 완전연결층(fully connected layer)의 출력 차원\n",
    "\n",
    "    - 해당 레이어의 유닛 수를 결정하는 매개변수로, 모델의 용량(capacity)에 영향을 미칩니다.\n",
    "    - 보통 units의 값은 트랜스포머의 차원인 d_model과 관련이 있습니다.\n",
    "    - 예를 들어, units=d_model*4와 같이 설정될 수 있습니다.\n",
    "    - 하지만 이는 일반적인 규칙은 아니며, 모델의 구조나 작업에 따라 최적의 값이 달라질 수 있습니다.\n",
    "\n",
    "- d_model : 트랜스포머 모델에서 사용되는 임베딩 벡터의 차원(또는 특징의 차원)\n",
    "\n",
    "    - 모델 내부에서 다양한 연산이 이루어지는 벡터의 차원으로, 트랜스포머의 핵심 파라미터 중 하나입니다.\n",
    "    - 트랜스포머의 인코더와 디코더에서는 입력된 단어의 임베딩이 d_model 차원을 갖도록 설계됩니다.\n",
    "    - 이 차원은 어텐션 메커니즘, 피드포워드 네트워크 등 다양한 연산에 적용되며, 모델의 용량(capacity)을 결정하는 중요한 요소 중 하나입니다.\n",
    "    - 일반적으로 d_model은 트랜스포머의 하이퍼파라미터 중 하나로 설정되며, 주로 256, 512, 1024 등의 값이 사용됩니다.\n",
    "    - 적절한 d_model의 선택은 모델의 학습과 일반화 성능에 영향을 미칩니다.\n",
    "\n",
    "- num_heads :\n",
    "\n",
    "    - 트랜스포머의 어텐션 메커니즘은 여러 헤드로 나누어져 병렬로 계산되고, 각 헤드의 출력이 합쳐져 최종 출력이 생성됩니다.\n",
    "      이렇게 함으로써 모델은 각 헤드가 서로 다른 측면에 집중하도록 학습하게 되어 다양한 특징을 추출할 수 있습니다.\n",
    "    - 일반적으로 num_heads는 8 또는 12와 같은 값으로 설정됩니다.\n",
    "    - 적절한 num_heads의 선택은 모델의 성능과 효율성(계산 비용 대비 더 많은 병렬 계산 수행)에 영향을 미치므로 조심스럽게 결정되어야 합니다.\n",
    "\n",
    "## 디코더\n",
    "### 디코더 층\n",
    "디코더는 인코더와 달리 3개의 서브 층으로 구성됩니다.   \n",
    "첫 번째는 셀프 어텐션, 두 번째는 인코더-디코더 어텐션, 세 번째는 피드 포워드 신경망입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82fb5057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    # inputs: 현재 디코더 레이어의 입력으로 들어가는 시퀀스.\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    # enc_outputs: 인코더의 출력. 디코더는 이를 참조하여 인코더-디코더 어텐션을 수행.\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    # look_ahead_mask: 디코더 셀프 어텐션에서 사용되는 마스크. 현재 위치 이후의 토큰에 대한 정보를 가립니다.\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    # padding_mask: 패딩을 처리하기 위한 마스크. 패딩 토큰에 대한 어텐션을 제한합니다.\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    # 이는 현재 위치의 단어에 주목하면서 인코더의 다른 단어들 간의 관계를 고려합니다.\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    # 디코더가 인코더의 출력을 참조하여 현재 위치의 단어와 인코더의 단어 간의 관계를 고려합니다.\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층을 거쳐 최종 출력을 얻습니다.\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cee613",
   "metadata": {},
   "source": [
    "### 디코더 층을 쌓아 디코더 만들기\n",
    "이렇게 구현한 디코더의 층은 임베딩 층(Embedding layer) 과 포지셔널 인코딩(Positional Encoding) 을 연결하고,  \n",
    "사용자가 원하는 만큼 디코더 층을 쌓아 트랜스포머의 디코더가 완성됩니다.  \n",
    "\n",
    "인코더와 마찬가지로 num_layers 개수의 디코더 층을 쌓습니다.  \n",
    "논문에서는 총 6개의 디코더 층을 사용하였지만, 실습에서는 학습 시간을 고려하여 그보다 적은 개수를 사용할 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc10650f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 구현\n",
    "\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')   # inputs: 디코더의 입력으로 들어가는 시퀀스.\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')   # enc_outputs: 인코더의 출력. 디코더는 이를 참조하여 인코더-디코더 어텐션을 수행.\n",
    "    # look_ahead_mask: 디코더의 셀프 어텐션에서 사용되는 마스크. 현재 위치 이후의 토큰에 대한 정보를 가립니다.\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크 : 패딩을 처리하기 위한 마스크. 패딩 토큰에 대한 어텐션을 제한합니다.\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)   # 입력 시퀀스를 임베딩 레이어를 통해 임베딩\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))   # 스케일을 조절\n",
    "\n",
    "  # 포지셔널 인코딩 : 단어의 위치 정보를 추가\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행 : 과적합 방지를 위해 일부 토큰을 랜덤하게 제거\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 디코더 레이어 쌓기 (num_layers 개수만큼)\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "    # 디코더 레이어의 입력은 이전 레이어의 출력인 outputs와 함께 인코더의 출력(enc_outputs), 셀프 어텐션 마스크(look_ahead_mask), 패딩 마스크(padding_mask)를 받습니다.\n",
    "\n",
    "    # 입력과 출력을 정의한 후, 해당 디코더 모델을 반환\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15954209",
   "metadata": {},
   "source": [
    "인코더와 디코더 층을 각각 함수로 구현하였습니다.  \n",
    "이를 하나로 조합하여 트랜스포머 모델을 만들어보겠습니다.  \n",
    "\n",
    "## 트랜스포머 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65dae8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 트랜스포머 함수 정의\n",
    "\n",
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")             # 인코더의 입력 텐서\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")     # 디코더의 입력 텐서\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크 : 인코더 입력에 대한 패딩 마스크를 생성 (패딩 토큰을 가리기 위해 사용됨)\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크(가리기) 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크 : 디코더 입력에 대한 패딩 마스크를 생성\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더 : 인코더 레이어를 호출하여 인코더의 출력을 얻는다. (인코더의 입력으로 inputs, enc_padding_mask를 사용한다.)\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더 : 디코더 레이어를 호출하여 디코더의 출력을 얻는다. \n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층 : 디코더의 출력을 완결연결층에 통과시켜 최종 출력을 얻는다. (출력의 크기는 어휘 사전의 크기인 vocab_size와 같음.)\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    # 최족적으로 모델은 'inputs'과 'dec_inputs'을 입력으로 받고, 'outputs'을 출력으로 하는 트랜스포머 모델을 반환한다.\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91ffba0",
   "metadata": {},
   "source": [
    "## 모델 생성\n",
    "num_layers, d-Model, units는 전부 사용자가 정할 수 있는 하이퍼파라미터 값입니다.  \n",
    "논문에서처럼 num_layers는 6, d-Model은 512로 각 하이퍼파라미터를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "852cdf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 512)    13630976    inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 512)    19940864    dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8131)   4171203     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 37,743,043\n",
      "Trainable params: 37,743,043\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574951bc",
   "metadata": {},
   "source": [
    "## 손실 함수(Loss function)\n",
    "레이블인 시퀀스에 패딩이 되어 있으므로, loss를 계산할 때 패딩 마스크를 적용해야 합니다.  \n",
    "여기서 사용되는 손실 함수는 SparseCategoricalCrossentropy로, 희소한 레이블에 대한 다중 분류 손실을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e411b602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 손실함수 구현\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "    # 정답 레이블 y_true를 모델의 출력 y_pred와 크기를 맞추기 위해 재구성.\n",
    "    # -1은 해당 차원의 크기를 자동으로 계산하라는 의미. 각 시퀀스의 길이는 MAX_LENGTH - 1로 설정되어 있음.\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "    # 재구성된 정답 레이블 y_true와 모델의 예측값 y_pred를 사용하여 희소 범주형 크로스엔트로피 손실을 계산\n",
    "    # from_logits=True는 y_pred가 확률 분포가 아니라 로짓(확률에 대한 로그 오즈 비율)을 포함하고 있음을 나타냄\n",
    "    # reduction='none'은 손실의 각 샘플에 대한 값을 유지하도록 지정\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    # '패딩된 부분을 나타내는 값인 0'이 아닌 부분을 1로 표시하는 마스크를 생성. 이 마스크는 손실을 계산할 때 패딩된 부분(0)을 무시하는 데 사용됨.\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    # 손실에 마스크를 적용하여 패딩된 부분의 손실을 0으로 만든다.\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "    # 마지막으로, 손실의 평균을 계산하여 반환합니다. \n",
    "    # 평균을 구하는 이유는 시퀀스의 길이가 다를 수 있기 때문에 각 시퀀스의 손실을 비교 가능한 형태로 만들기 위함입니다.\n",
    "  return tf.reduce_mean(loss)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e8e4ba",
   "metadata": {},
   "source": [
    "## 커스텀 된 학습률(Learning rate)\n",
    "최근에는 모델학습 초기에 learning rate를 급격히 높였다가, 이후 train step이 진행됨에 따라 서서히 낮추어 가면서 안정적으로 수렴하게 하는 고급 기법을 널리 사용하고 있습니다.\n",
    "이러한 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)을 통한 아담 옵티마이저를 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9c9ecec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 커스텀 학습률 스케줄러\n",
    "\n",
    "# CustomSchedule 클래스는 tf.keras.optimizers.schedules.LearningRateSchedule 클래스를 상속\n",
    "# 이 클래스에서는 초기 학습률을 1/sqrt(d_model)로 설정하고, warm-up 단계 동안은 선형적으로 증가하도록 설계되어 있다.\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    # d_model은 모델의 내부 차원 수를 나타내며, warmup_steps는 학습률이 선형적으로 증가하는 단계 수\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "    # __call__ 메서드에서는 현재의 학습 단계(step)을 받아서 해당 단계에 대한 학습률을 계산.\n",
    "  def __call__(self, step):\n",
    "    # arg1 및 arg2는 선형적인 증가 부분을 조절하기 위한 인자들\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    # 최종적으로는 arg1과 arg2 중 작은 값을 선택하여 반환합니다.\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0151217",
   "metadata": {},
   "source": [
    "방금 정의한 커스텀 학습률 스케줄링 계획을 시각화해 봅니다.  \n",
    "학습 초기에는 learning_rate가 step_num에 비례해서 증가하다가 이후로는 감소하는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53ebb02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 커스텀 학습률 스케줄링 계획 시각화 \n",
    "\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))   # tf.range(200000, dtype=tf.float32)는 학습 단계(step)\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87fa47d",
   "metadata": {},
   "source": [
    "## 모델 컴파일\n",
    "손실 함수와 커스텀 된 학습률(learning rate)을 사용하여 모델을 컴파일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "447bd33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# model compile\n",
    "\n",
    "# CustomSchedule 클래스를 사용하여 학습률(learning rate)을 동적으로 조정합니다. \n",
    "# 이 학습률은 Adam 옵티마이저에 적용됩니다. D_MODEL은 모델 내부의 입출력 차원을 나타냅니다.\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "# Adam 옵티마이저를 정의하고, 학습률을 지정합니다. beta_1, beta_2, epsilon 등은 Adam 옵티마이저의 하이퍼파라미터입니다.\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa66bd2",
   "metadata": {},
   "source": [
    "## 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dea79b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "185/185 [==============================] - 56s 217ms/step - loss: 1.3517 - accuracy: 0.0228\n",
      "Epoch 2/20\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 1.0716 - accuracy: 0.0496\n",
      "Epoch 3/20\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.9818 - accuracy: 0.0508\n",
      "Epoch 4/20\n",
      "185/185 [==============================] - 40s 216ms/step - loss: 0.9382 - accuracy: 0.0528\n",
      "Epoch 5/20\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.9025 - accuracy: 0.0551\n",
      "Epoch 6/20\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.8664 - accuracy: 0.0568\n",
      "Epoch 7/20\n",
      "185/185 [==============================] - 40s 216ms/step - loss: 0.8293 - accuracy: 0.0592\n",
      "Epoch 8/20\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.7847 - accuracy: 0.0618\n",
      "Epoch 9/20\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.7346 - accuracy: 0.0652\n",
      "Epoch 10/20\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.6816 - accuracy: 0.0695\n",
      "Epoch 11/20\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.6254 - accuracy: 0.0749\n",
      "Epoch 12/20\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.5680 - accuracy: 0.0814\n",
      "Epoch 13/20\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.5122 - accuracy: 0.0878\n",
      "Epoch 14/20\n",
      "185/185 [==============================] - 40s 216ms/step - loss: 0.4604 - accuracy: 0.0947\n",
      "Epoch 15/20\n",
      "185/185 [==============================] - 40s 216ms/step - loss: 0.4124 - accuracy: 0.1012\n",
      "Epoch 16/20\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.3739 - accuracy: 0.1065\n",
      "Epoch 17/20\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.3381 - accuracy: 0.1113\n",
      "Epoch 18/20\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.3098 - accuracy: 0.1147\n",
      "Epoch 19/20\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.2864 - accuracy: 0.1181\n",
      "Epoch 20/20\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.2685 - accuracy: 0.1204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f127052c8e0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model fit\n",
    "\n",
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a35cb9",
   "metadata": {},
   "source": [
    "# Step 5. 모델 평가하기\n",
    "아래의 예측 단계로 챗봇을 테스트해보겠습니다.  \n",
    "\n",
    "1. 새로운 입력 문장에 대해서는 훈련 때와 동일한 전처리를 거친다.\n",
    "2. 입력 문장을 토크나이징하고, START_TOKEN과 END_TOKEN을 추가한다.\n",
    "3. 패딩 마스킹과 룩 어헤드 마스킹을 계산한다.\n",
    "4. 디코더는 입력 시퀀스로부터 다음 단어를 예측한다.\n",
    "5. 디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
    "6. END_TOKEN이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춘다.\n",
    "\n",
    "위의 과정을 모두 담은 decoder_inference() 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1fe02b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 예측 단계 : decoder_inference() 함수 구현\n",
    "\n",
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]   # 마지막 시점의 정보만 선택\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    # 주어진 텐서 predictions에서 마지막 차원(가장 안쪽의 차원 / axis=1 / 어휘 크기)을 따라 최댓값을 가지는 요소의 인덱스를 반환\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료 (END_TOKEN[0]은 종료 토큰의 정수 인덱스)\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    # output_sequence 텐서에서 크기가 1인 차원을 제거 (디코더의 인퍼런스 프로세스 중에 생성된 시퀀스를 반환할 때 사용됨)\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "\n",
    "# 기본적으로 디코더의 인퍼런스는 현재까지의 예측된 시퀀스를 계속해서 누적하면서 진행됩니다. \n",
    "# 그러나 모델의 출력이 배치 차원을 가지고 있기 때문에, 이를 제거하고 최종 시퀀스를 반환하기 위해 tf.squeeze를 사용합니다. \n",
    "# 반환된 시퀀스는 실제 단어의 인덱스를 포함하며, 이는 모델이 생성한 문장입니다.\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650f18af",
   "metadata": {},
   "source": [
    "임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는 sentence_generation() 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de8d5c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 챗봇의 대답을 얻는 함수 구현 : decoder_inference() 함수를 호출하여\n",
    "\n",
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff5596d",
   "metadata": {},
   "source": [
    "### 임의의 문장으로부터 챗봇의 대답을 얻어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5bdf8c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 여행가고 싶다!!\n",
      "출력 : 시원한 쥬스는 어때요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'시원한 쥬스는 어때요 .'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('여행가고 싶다!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed18cc4f",
   "metadata": {},
   "source": [
    "## 초기 실험\n",
    "#### 하이퍼파라미터   \n",
    "- num_layers=6\n",
    "- d-Model=512\n",
    "- EPOCHS=20\n",
    "\n",
    "#### 결과\n",
    "loss: 0.2685 - accuracy: 0.1204 이며,  \n",
    "임의의 문장을 입력했을 때 나오는 답변도 맥락에 맞지 않습니다.  \n",
    "\n",
    "Epochs을 높이고, 배치 사이즈를 64에서 32로 조정하여 다시 학습해보겠습니다.  \n",
    "## 실험1 : BATCH_SIZE 64에서 32로 조정, EPOCHS 20에서 30으로 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c257afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "492cc335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# model compile\n",
    "\n",
    "# CustomSchedule 클래스를 사용하여 학습률(learning rate)을 동적으로 조정합니다. \n",
    "# 이 학습률은 Adam 옵티마이저에 적용됩니다. D_MODEL은 모델 내부의 입출력 차원을 나타냅니다.\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "# Adam 옵티마이저를 정의하고, 학습률을 지정합니다. beta_1, beta_2, epsilon 등은 Adam 옵티마이저의 하이퍼파라미터입니다.\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "132f5ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "185/185 [==============================] - 40s 216ms/step - loss: 0.1895 - accuracy: 0.1349\n",
      "Epoch 2/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1637 - accuracy: 0.1403\n",
      "Epoch 3/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1485 - accuracy: 0.1436\n",
      "Epoch 4/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1398 - accuracy: 0.1451\n",
      "Epoch 5/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1338 - accuracy: 0.1459\n",
      "Epoch 6/30\n",
      "185/185 [==============================] - 40s 216ms/step - loss: 0.1290 - accuracy: 0.1465\n",
      "Epoch 7/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1257 - accuracy: 0.1466\n",
      "Epoch 8/30\n",
      "185/185 [==============================] - 40s 216ms/step - loss: 0.1233 - accuracy: 0.1468\n",
      "Epoch 9/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1207 - accuracy: 0.1467\n",
      "Epoch 10/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1200 - accuracy: 0.1466\n",
      "Epoch 11/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1183 - accuracy: 0.1467\n",
      "Epoch 12/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1186 - accuracy: 0.1462\n",
      "Epoch 13/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1173 - accuracy: 0.1465\n",
      "Epoch 14/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1202 - accuracy: 0.1456\n",
      "Epoch 15/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1212 - accuracy: 0.1451\n",
      "Epoch 16/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1223 - accuracy: 0.1446\n",
      "Epoch 17/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1233 - accuracy: 0.1441\n",
      "Epoch 18/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1289 - accuracy: 0.1430\n",
      "Epoch 19/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1311 - accuracy: 0.1427\n",
      "Epoch 20/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1320 - accuracy: 0.1424\n",
      "Epoch 21/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1361 - accuracy: 0.1414\n",
      "Epoch 22/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1396 - accuracy: 0.1407\n",
      "Epoch 23/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1339 - accuracy: 0.1417\n",
      "Epoch 24/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1273 - accuracy: 0.1431\n",
      "Epoch 25/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1190 - accuracy: 0.1447\n",
      "Epoch 26/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1128 - accuracy: 0.1464\n",
      "Epoch 27/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.1066 - accuracy: 0.1475\n",
      "Epoch 28/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0990 - accuracy: 0.1492\n",
      "Epoch 29/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0949 - accuracy: 0.1501\n",
      "Epoch 30/30\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0890 - accuracy: 0.1514\n"
     ]
    }
   ],
   "source": [
    "# model fit _에폭 20에서 30으로 조정\n",
    "\n",
    "EPOCHS = 30\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "936929ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프로 시각화\n",
    "\n",
    "plt.plot(history.history['loss'], label='Loss', marker='o')\n",
    "plt.plot(history.history['accuracy'], label='Accuracy', marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d377b5",
   "metadata": {},
   "source": [
    "초기 학습에서 이어서 학습이 진행된 것으로 보입니다.  \n",
    "accuracy는 소폭 상승하고 있으며, loss는 0.0890 수준으로 떨어졌습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d37fbb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 카페갈래?\n",
      "출력 : 상관없어요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'상관없어요 .'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의의 문장으로 테스트 해보기\n",
    "sentence_generation('카페갈래?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8a2afb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 고민이 있어\n",
      "출력 : 연락을 하셨군요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'연락을 하셨군요 .'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의의 문장으로 테스트 해보기\n",
    "sentence_generation('고민이 있어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac79ca16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : AI 공부가 쉽지가 않네.\n",
      "출력 : 항상 함께였을테니까요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'항상 함께였을테니까요 .'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의의 문장으로 테스트 해보기\n",
    "sentence_generation('AI 공부가 쉽지가 않네.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7981edc6",
   "metadata": {},
   "source": [
    "답변에 대한 의도는 느껴지지만 맥락에 아주 잘 맞는 답변이라고 느껴지지는 않습니다.  \n",
    "3번째 문장의 경우 영어에 대해서는 전처리하지 않았던 것을 깨달아 이후 버전 파일에서는 영어 전처리를 하고 진행하겠습니다.  \n",
    "에폭을 늘렸을 때 조금은 향상된 것으로 보여 이후 실험에서는 더 많은 에폭으로 실험해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd9f725",
   "metadata": {},
   "source": [
    "## 실험2 : BATCH_SIZE=64, EPOCHS 30에서 200으로 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d81315e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "79b427e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# model compile\n",
    "\n",
    "# CustomSchedule 클래스를 사용하여 학습률(learning rate)을 동적으로 조정합니다. \n",
    "# 이 학습률은 Adam 옵티마이저에 적용됩니다. D_MODEL은 모델 내부의 입출력 차원을 나타냅니다.\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "# Adam 옵티마이저를 정의하고, 학습률을 지정합니다. beta_1, beta_2, epsilon 등은 Adam 옵티마이저의 하이퍼파라미터입니다.\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "60ad8cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "185/185 [==============================] - 56s 216ms/step - loss: 0.0509 - accuracy: 0.1612\n",
      "Epoch 2/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0387 - accuracy: 0.1645\n",
      "Epoch 3/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0300 - accuracy: 0.1673\n",
      "Epoch 4/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0259 - accuracy: 0.1685\n",
      "Epoch 5/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0248 - accuracy: 0.1688\n",
      "Epoch 6/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0245 - accuracy: 0.1688\n",
      "Epoch 7/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0257 - accuracy: 0.1683\n",
      "Epoch 8/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0266 - accuracy: 0.1680\n",
      "Epoch 9/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0287 - accuracy: 0.1673\n",
      "Epoch 10/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0306 - accuracy: 0.1666\n",
      "Epoch 11/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0328 - accuracy: 0.1659\n",
      "Epoch 12/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0355 - accuracy: 0.1650\n",
      "Epoch 13/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0398 - accuracy: 0.1639\n",
      "Epoch 14/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0424 - accuracy: 0.1630\n",
      "Epoch 15/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0469 - accuracy: 0.1616\n",
      "Epoch 16/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0510 - accuracy: 0.1607\n",
      "Epoch 17/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0556 - accuracy: 0.1595\n",
      "Epoch 18/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0605 - accuracy: 0.1582\n",
      "Epoch 19/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0662 - accuracy: 0.1569\n",
      "Epoch 20/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0709 - accuracy: 0.1558\n",
      "Epoch 21/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0746 - accuracy: 0.1550\n",
      "Epoch 22/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0814 - accuracy: 0.1534\n",
      "Epoch 23/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0820 - accuracy: 0.1533\n",
      "Epoch 24/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0751 - accuracy: 0.1550\n",
      "Epoch 25/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0739 - accuracy: 0.1553\n",
      "Epoch 26/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0697 - accuracy: 0.1562\n",
      "Epoch 27/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0659 - accuracy: 0.1573\n",
      "Epoch 28/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0625 - accuracy: 0.1578\n",
      "Epoch 29/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0589 - accuracy: 0.1585\n",
      "Epoch 30/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0570 - accuracy: 0.1592\n",
      "Epoch 31/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0549 - accuracy: 0.1598\n",
      "Epoch 32/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0506 - accuracy: 0.1610\n",
      "Epoch 33/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0509 - accuracy: 0.1610\n",
      "Epoch 34/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0459 - accuracy: 0.1622\n",
      "Epoch 35/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0458 - accuracy: 0.1623\n",
      "Epoch 36/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0431 - accuracy: 0.1629\n",
      "Epoch 37/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0406 - accuracy: 0.1636\n",
      "Epoch 38/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0406 - accuracy: 0.1635\n",
      "Epoch 39/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0381 - accuracy: 0.1643\n",
      "Epoch 40/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0375 - accuracy: 0.1644\n",
      "Epoch 41/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0364 - accuracy: 0.1648\n",
      "Epoch 42/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0351 - accuracy: 0.1650\n",
      "Epoch 43/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0331 - accuracy: 0.1657\n",
      "Epoch 44/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0320 - accuracy: 0.1659\n",
      "Epoch 45/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0311 - accuracy: 0.1661\n",
      "Epoch 46/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0300 - accuracy: 0.1665\n",
      "Epoch 47/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0294 - accuracy: 0.1665\n",
      "Epoch 48/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0275 - accuracy: 0.1671\n",
      "Epoch 49/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0271 - accuracy: 0.1671\n",
      "Epoch 50/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0265 - accuracy: 0.1673\n",
      "Epoch 51/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0255 - accuracy: 0.1677\n",
      "Epoch 52/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0249 - accuracy: 0.1678\n",
      "Epoch 53/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0234 - accuracy: 0.1682\n",
      "Epoch 54/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0235 - accuracy: 0.1683\n",
      "Epoch 55/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0232 - accuracy: 0.1683\n",
      "Epoch 56/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0221 - accuracy: 0.1687\n",
      "Epoch 57/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0218 - accuracy: 0.1686\n",
      "Epoch 58/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0206 - accuracy: 0.1691\n",
      "Epoch 59/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0207 - accuracy: 0.1691\n",
      "Epoch 60/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0202 - accuracy: 0.1692\n",
      "Epoch 61/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0194 - accuracy: 0.1695\n",
      "Epoch 62/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0193 - accuracy: 0.1695\n",
      "Epoch 63/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0200 - accuracy: 0.1695\n",
      "Epoch 64/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0180 - accuracy: 0.1698\n",
      "Epoch 65/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0175 - accuracy: 0.1700\n",
      "Epoch 66/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0172 - accuracy: 0.1701\n",
      "Epoch 67/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0163 - accuracy: 0.1703\n",
      "Epoch 68/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0174 - accuracy: 0.1700\n",
      "Epoch 69/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0173 - accuracy: 0.1701\n",
      "Epoch 70/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0156 - accuracy: 0.1704\n",
      "Epoch 71/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0162 - accuracy: 0.1704\n",
      "Epoch 72/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0144 - accuracy: 0.1708\n",
      "Epoch 73/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0154 - accuracy: 0.1706\n",
      "Epoch 74/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0145 - accuracy: 0.1709\n",
      "Epoch 75/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0150 - accuracy: 0.1707\n",
      "Epoch 76/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0140 - accuracy: 0.1709\n",
      "Epoch 77/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0138 - accuracy: 0.1709\n",
      "Epoch 78/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0136 - accuracy: 0.1711\n",
      "Epoch 79/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0137 - accuracy: 0.1710\n",
      "Epoch 80/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0133 - accuracy: 0.1712\n",
      "Epoch 81/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0131 - accuracy: 0.1712\n",
      "Epoch 82/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0131 - accuracy: 0.1712\n",
      "Epoch 83/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0126 - accuracy: 0.1714\n",
      "Epoch 84/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0126 - accuracy: 0.1713\n",
      "Epoch 85/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0116 - accuracy: 0.1716\n",
      "Epoch 86/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0120 - accuracy: 0.1715\n",
      "Epoch 87/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0113 - accuracy: 0.1717\n",
      "Epoch 88/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0121 - accuracy: 0.1715\n",
      "Epoch 89/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0112 - accuracy: 0.1719\n",
      "Epoch 90/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0107 - accuracy: 0.1718\n",
      "Epoch 91/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0105 - accuracy: 0.1720\n",
      "Epoch 92/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0112 - accuracy: 0.1718\n",
      "Epoch 93/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0103 - accuracy: 0.1720\n",
      "Epoch 94/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0109 - accuracy: 0.1719\n",
      "Epoch 95/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0104 - accuracy: 0.1720\n",
      "Epoch 96/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0097 - accuracy: 0.1722\n",
      "Epoch 97/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0107 - accuracy: 0.1719\n",
      "Epoch 98/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0098 - accuracy: 0.1722\n",
      "Epoch 99/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0098 - accuracy: 0.1721\n",
      "Epoch 100/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0093 - accuracy: 0.1724\n",
      "Epoch 101/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0092 - accuracy: 0.1723\n",
      "Epoch 102/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0091 - accuracy: 0.1723\n",
      "Epoch 103/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0092 - accuracy: 0.1722\n",
      "Epoch 104/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0092 - accuracy: 0.1723\n",
      "Epoch 105/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0093 - accuracy: 0.1723\n",
      "Epoch 106/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0089 - accuracy: 0.1724\n",
      "Epoch 107/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0090 - accuracy: 0.1723\n",
      "Epoch 108/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0082 - accuracy: 0.1726\n",
      "Epoch 109/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0087 - accuracy: 0.1725\n",
      "Epoch 110/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0082 - accuracy: 0.1726\n",
      "Epoch 111/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0088 - accuracy: 0.1724\n",
      "Epoch 112/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0082 - accuracy: 0.1726\n",
      "Epoch 113/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0078 - accuracy: 0.1727\n",
      "Epoch 114/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0080 - accuracy: 0.1727\n",
      "Epoch 115/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0079 - accuracy: 0.1726\n",
      "Epoch 116/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0078 - accuracy: 0.1728\n",
      "Epoch 117/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0079 - accuracy: 0.1726\n",
      "Epoch 118/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0076 - accuracy: 0.1727\n",
      "Epoch 119/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0073 - accuracy: 0.1728\n",
      "Epoch 120/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0073 - accuracy: 0.1728\n",
      "Epoch 121/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0073 - accuracy: 0.1729\n",
      "Epoch 122/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0078 - accuracy: 0.1727\n",
      "Epoch 123/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0077 - accuracy: 0.1728\n",
      "Epoch 124/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0068 - accuracy: 0.1730\n",
      "Epoch 125/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0072 - accuracy: 0.1729\n",
      "Epoch 126/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0074 - accuracy: 0.1729\n",
      "Epoch 127/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0068 - accuracy: 0.1730\n",
      "Epoch 128/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0067 - accuracy: 0.1730\n",
      "Epoch 129/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0069 - accuracy: 0.1729\n",
      "Epoch 130/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0067 - accuracy: 0.1730\n",
      "Epoch 131/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0065 - accuracy: 0.1730\n",
      "Epoch 132/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0067 - accuracy: 0.1730\n",
      "Epoch 133/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0065 - accuracy: 0.1730\n",
      "Epoch 134/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0066 - accuracy: 0.1731\n",
      "Epoch 135/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0063 - accuracy: 0.1731\n",
      "Epoch 136/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0061 - accuracy: 0.1732\n",
      "Epoch 137/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0065 - accuracy: 0.1731\n",
      "Epoch 138/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0063 - accuracy: 0.1731\n",
      "Epoch 139/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0062 - accuracy: 0.1732\n",
      "Epoch 140/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0058 - accuracy: 0.1732\n",
      "Epoch 141/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0061 - accuracy: 0.1732\n",
      "Epoch 142/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0060 - accuracy: 0.1732\n",
      "Epoch 143/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0057 - accuracy: 0.1732\n",
      "Epoch 144/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0059 - accuracy: 0.1732\n",
      "Epoch 145/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0056 - accuracy: 0.1733\n",
      "Epoch 146/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0058 - accuracy: 0.1733\n",
      "Epoch 147/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0054 - accuracy: 0.1733\n",
      "Epoch 148/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0055 - accuracy: 0.1733\n",
      "Epoch 149/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0058 - accuracy: 0.1733\n",
      "Epoch 150/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0055 - accuracy: 0.1734\n",
      "Epoch 151/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0055 - accuracy: 0.1734\n",
      "Epoch 152/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0055 - accuracy: 0.1733\n",
      "Epoch 153/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0060 - accuracy: 0.1732\n",
      "Epoch 154/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0059 - accuracy: 0.1732\n",
      "Epoch 155/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0053 - accuracy: 0.1733\n",
      "Epoch 156/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0055 - accuracy: 0.1733\n",
      "Epoch 157/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0056 - accuracy: 0.1733\n",
      "Epoch 158/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0053 - accuracy: 0.1734\n",
      "Epoch 159/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0052 - accuracy: 0.1734\n",
      "Epoch 160/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0051 - accuracy: 0.1734\n",
      "Epoch 161/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0051 - accuracy: 0.1734\n",
      "Epoch 162/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0052 - accuracy: 0.1734\n",
      "Epoch 163/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0048 - accuracy: 0.1735\n",
      "Epoch 164/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0052 - accuracy: 0.1735\n",
      "Epoch 165/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0054 - accuracy: 0.1734\n",
      "Epoch 166/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0051 - accuracy: 0.1735\n",
      "Epoch 167/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0047 - accuracy: 0.1735\n",
      "Epoch 168/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0052 - accuracy: 0.1735\n",
      "Epoch 169/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0048 - accuracy: 0.1736\n",
      "Epoch 170/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0047 - accuracy: 0.1735\n",
      "Epoch 171/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0047 - accuracy: 0.1735\n",
      "Epoch 172/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0050 - accuracy: 0.1735\n",
      "Epoch 173/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0046 - accuracy: 0.1736\n",
      "Epoch 174/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0047 - accuracy: 0.1735\n",
      "Epoch 175/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0049 - accuracy: 0.1734\n",
      "Epoch 176/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0048 - accuracy: 0.1735\n",
      "Epoch 177/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0045 - accuracy: 0.1737\n",
      "Epoch 178/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0046 - accuracy: 0.1736\n",
      "Epoch 179/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0047 - accuracy: 0.1736\n",
      "Epoch 180/200\n",
      "185/185 [==============================] - 40s 215ms/step - loss: 0.0045 - accuracy: 0.1736\n",
      "Epoch 181/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0044 - accuracy: 0.1737\n",
      "Epoch 182/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0046 - accuracy: 0.1735\n",
      "Epoch 183/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0046 - accuracy: 0.1736\n",
      "Epoch 184/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0045 - accuracy: 0.1736\n",
      "Epoch 185/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0045 - accuracy: 0.1736\n",
      "Epoch 186/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0045 - accuracy: 0.1736\n",
      "Epoch 187/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0044 - accuracy: 0.1736\n",
      "Epoch 188/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0044 - accuracy: 0.1736\n",
      "Epoch 189/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0046 - accuracy: 0.1736\n",
      "Epoch 190/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0043 - accuracy: 0.1737\n",
      "Epoch 191/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0043 - accuracy: 0.1736\n",
      "Epoch 192/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0045 - accuracy: 0.1736\n",
      "Epoch 193/200\n",
      "185/185 [==============================] - 39s 213ms/step - loss: 0.0042 - accuracy: 0.1737\n",
      "Epoch 194/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0043 - accuracy: 0.1736\n",
      "Epoch 195/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0040 - accuracy: 0.1737\n",
      "Epoch 196/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0044 - accuracy: 0.1736\n",
      "Epoch 197/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0042 - accuracy: 0.1737\n",
      "Epoch 198/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0040 - accuracy: 0.1738\n",
      "Epoch 199/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0042 - accuracy: 0.1737\n",
      "Epoch 200/200\n",
      "185/185 [==============================] - 40s 214ms/step - loss: 0.0041 - accuracy: 0.1737\n"
     ]
    }
   ],
   "source": [
    "# model fit _에폭 30에서 200으로 조정\n",
    "\n",
    "EPOCHS = 200\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dcd81760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 고민이 있어\n",
      "출력 : 연락을 하셨군요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'연락을 하셨군요 .'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의의 문장으로 테스트 해보기\n",
    "sentence_generation('고민이 있어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2771ea50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6163</th>\n",
       "      <td>또 일주일도 못가서ㅎㅎ</td>\n",
       "      <td>연락을 하셨군요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q          A  label\n",
       "6163  또 일주일도 못가서ㅎㅎ  연락을 하셨군요.      1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 맥락에 맞지 않는 답변이므로 데이터셋에 비슷한 answer가 있는지 확인해보기\n",
    "data[data['A'] == '연락을 하셨군요.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47e30d1",
   "metadata": {},
   "source": [
    "연관성을 찾기 어려워보입니다.  \n",
    "데이터셋에 있는 질문으로 테스트 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7cd3423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 결정은 빠르면 빠를 수록 좋겠지?\n",
      "출력 : 자신을 위한 결정을 내리길 바라요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'자신을 위한 결정을 내리길 바라요 .'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋의 문장으로 테스트 해보기\n",
    "sentence_generation('결정은 빠르면 빠를 수록 좋겠지?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "03dfce1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 내일이 기대돼\n",
      "출력 : 좋은 결과길 바라요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 결과길 바라요 .'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋의 문장으로 테스트 해보기 - 2\n",
    "sentence_generation('내일이 기대돼')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "33eb1bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>내일이 기대돼</td>\n",
       "      <td>좋은 일이 생길 거예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Q              A  label\n",
       "909  내일이 기대돼  좋은 일이 생길 거예요.      0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋의 실제 정답 확인\n",
    "data[data['Q'] == '내일이 기대돼']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd99801e",
   "metadata": {},
   "source": [
    "맥락에 맞는 다른 답변이 출력되었습니다. 데이터셋 내의 다른 질문도 테스트해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "64ccb0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 게임 같이 하자고 할까?\n",
      "출력 : 안 될 것도 없죠 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안 될 것도 없죠 .'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋의 문장으로 테스트 해보기 - 3\n",
    "sentence_generation(data['Q'][125])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e3208ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안 될 것도 없죠.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋의 실제 정답 확인\n",
    "data['A'][125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bd3d72df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 타이밍이 진짜 기막혀\n",
      "출력 : 그럴 때가 있어요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'그럴 때가 있어요 .'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋의 문장으로 테스트 해보기 - 4\n",
    "sentence_generation('타이밍이 진짜 기막혀')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "921c797b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>타이밍이 진짜 기막혀</td>\n",
       "      <td>그럴 때가 있어요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Q           A  label\n",
       "4795  타이밍이 진짜 기막혀  그럴 때가 있어요.      0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋의 실제 정답 확인\n",
    "data[data['Q'] == '타이밍이 진짜 기막혀']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c94784",
   "metadata": {},
   "source": [
    "데이터셋의 질문에는 데이터셋의 답변들이 잘 나옵니다.  \n",
    "또한 에폭을 크게 높인다고 해서 accuracy가 드라마틱하게 높아지지 않음을 확인하였습니다.  \n",
    "따라서 다음 실험에서는 다른 하이퍼파라미터를 변경하며 성능을 향상시켜보고자 합니다.\n",
    "\n",
    "### 다음 노트북 파일에서는\n",
    "- 일반화 성능을 높이기 위해 드롭아웃 0.5로 설정하여 다시 학습을 진행\n",
    "- 영어, 숫자 관련 전처리 추가  \n",
    "하여 진행해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83161522",
   "metadata": {},
   "source": [
    "---\n",
    "## 회고\n",
    "### KEEP\n",
    "- 어려운 개념들을 찾아 주석을 달면서 천천히 뜯어보았다.\n",
    "- 전체 흐름과 개념들을 이해하기 위해 다른 자료들을 보며 익혔다.\n",
    "\n",
    "### PROBLEM\n",
    "- 모델 구조가 복잡하고 개념들이 어려워서 전반적인 단계가 아직 익숙하지 않다.\n",
    "- 사용되는 함수가 너무 많아서 그 함수가 어디에서 사용되는지 정리가 안된다.\n",
    "- 벡터 개념을 나올 때마다 대략적으로 이해하고 넘어가서 벡터 개념이 나올 때마다 계속 낯설다\n",
    "\n",
    "### TRY\n",
    "- 전체 단계와 각 단계에서의 핵심 개념을 정리하며 흐름을 익힌다. [복습 시 참고 자료](https://wikidocs.net/89786)\n",
    "- 각 함수의 기능을 다시 익히고, 함수의 구체적인 작동 방법과 코드를 익히며 프로그래밍 부분도 복습한다.\n",
    "- 벡터 관련한 간단한 개념과 예제들을 풀어본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19f8214",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- [트랜스포머 모델, 작동 방식](https://www.youtube.com/watch?v=6s69XY025MU)\n",
    "- [한국어 띄어쓰기, 맞춤법 검사 패키지](https://uding.tistory.com/11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d33694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
